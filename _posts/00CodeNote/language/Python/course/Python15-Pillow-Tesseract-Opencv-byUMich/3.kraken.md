
# Kraken


[toc]


---

## basic

```python
import kraken
help(kraken)
```


---

## from kraken import pageseg


1. simple two column text and then a list of lists which are the bounding boxes of lines of that text.

    ```py
    from kraken import pageseg
    from PIL import Image

    im=Image.open("readonly/two_col.png")

    # display the image inline
    display(im)

    # convert it to black and white
    # segment it up into lines with kraken
    bounding_boxes=pageseg.segment(im.convert('1'))['boxes']

    # print those lines to the screen
    print(bounding_boxes)
    ```

![download](https://i.imgur.com/NfbVh8z.png)

```
    [[100, 50, 449, 74], [131, 88, 414, 120], [59, 196, 522, 229], [18, 239, 522, 272], [19, 283, 522, 316], [19, 327, 525, 360], [19, 371, 523, 404], [18, 414, 524, 447], [17, 458, 522, 491], [19, 502, 141, 535], [58, 546, 521, 579], [18, 589, 522, 622], [19, 633, 521, 665], [563, 21, 1066, 54], [564, 64, 1066, 91], [563, 108, 1066, 135], [564, 152, 1065, 179], [563, 196, 1065, 229], [563, 239, 1066, 272], [562, 283, 909, 316], [600, 327, 1066, 360], [562, 371, 1066, 404], [562, 414, 1066, 447], [563, 458, 1065, 485], [563, 502, 1065, 535], [562, 546, 1066, 579], [562, 589, 1064, 622], [562, 633, 1066, 660], [18, 677, 833, 704], [18, 721, 1066, 754], [18, 764, 1065, 797], [17, 808, 1065, 841], [18, 852, 1067, 885], [18, 895, 1065, 928], [17, 939, 1065, 972], [17, 983, 1067, 1016], [18, 1027, 1065, 1060], [18, 1070, 1065, 1103], [18, 1114, 1065, 1147]]

```

2. make it clear

    ```py
    def show_boxes(img):
        # bring in ImageDraw object
        from PIL import ImageDraw
        # grab a drawing object to annotate that image
        drawing_object=ImageDraw.Draw(img)

        # create boxes using pageseg.segment
        bounding_boxes=pageseg.segment(img.convert('1'))['boxes']


        for box in bounding_boxes:
            # draw a nice rectangle
            drawing_object.rectangle(box, fill = None, outline ='red')
        # And to make it easy, lets return the image object
        return img

    # display
    display(show_boxes(Image.open("readonly/two_col.png")))
    ```

![download-1](https://i.imgur.com/VbLZmzF.png)


3. separate the gap

```py

# the black_colseps parameter. If set to True, kraken will assume that columns will be separated by black lines. This isn't our case here, but, can change the source image to have a black separator between columns.

def show_boxes(img):
    '''Modifies the passed image to show a series of bounding boxes on an image as run by kraken
    :param img: A PIL.Image object
    :return img: The modified PIL.Image object
    '''

    from PIL import ImageDraw
    drawing_object=ImageDraw.Draw(img)

    # create a set of boxes using pageseg.segment
    bounding_boxes=pageseg.segment(img.convert('1'), black_colseps=True)['boxes']


    for box in bounding_boxes:
        drawing_object.rectangle(box, fill = None, outline ='red')   # draw a rectangle
    return img

display(show_boxes(Image.open("readonly/two_col.png")))



# to detect a white column separator.
# add the separator if the space of was at least 25 pixels wide, roughly the width of a character, and six lines high.
# The width is easy, lets just make a variable
char_width=25



# The height is harder, since it depends on the height of the text. I'm going to write a routine
# to calculate the average height of a line
def calculate_line_height(img):
    '''Calculates the average height of a line from a given image
    :param img: A PIL.Image object
    :return: The average line height in pixels
    '''

    bounding_boxes=pageseg.segment(img.convert('1'))['boxes']
    # Each box is a tuple of (top, left, bottom, right)
    # the height: top - bottom
    height_accumulator=0
    for box in bounding_boxes:
        height_accumulator=height_accumulator+box[3]-box[1]
        # this is a bit tricky, remember that we start counting at the upper left corner in PIL!
    # now lets just return the average height
    # lets change it to the nearest full pixel by making it an integer
    return int(height_accumulator/len(bounding_boxes))

line_height=calculate_line_height(Image.open("readonly/two_col.png")) # 31


# scan through the image - looking at each pixel in turn - to determine if there is a block of whitespace.
gap_box=(0,0,char_width,line_height*6)



# It seems we will want to have a function which, given a pixel in an image, can check to see
# if that pixel has whitespace to the right and below it. Essentially, we want to test to see
# if the pixel is the upper left corner of something that looks like the gap_box. If so, then
# we should insert a line to "break up" this box before sending to kraken

def gap_check(img, location):
    '''Checks the img in a given (x,y) location to see if it fits the description of a gap_box
    :param img: A PIL.Image file
    :param location: A tuple (x,y) which is a pixel location in that image
    :return: True if that fits the definition of a gap_box, otherwise False
    '''
    # Recall that we can get a pixel using the img.getpixel() function. It returns this value
    # as a tuple of integers, one for each color channel. Our tools all work with binarized
    # images (black and white), so we should just get one value. If the value is 0 it's a black
    # pixel, if it's white then the value should be 255
    #
    # We're going to assume that the image is in the correct mode already, e.g. it has been
    # binarized. The algorithm to check our bounding box is fairly easy: we have a single location
    # which is our start and then we want to check all the pixels to the right of that location
    # up to gap_box[2]
    for x in range(location[0], location[0]+gap_box[2]):
        # the height is similar, so lets iterate a y variable to gap_box[3]
        for y in range(location[1], location[1]+gap_box[3]):
            # we want to check if the pixel is white, but only if we are still within the image
            if x < img.width and y < img.height:
                # if the pixel is white we don't do anything, if it's black, we just want to
                # finish and return False
                if img.getpixel((x,y)) != 255:
                    return False
    # If we have managed to walk all through the gap_box without finding any non-white pixels
    # then we can return true -- this is a gap!
    return True


# once find a gap, draw a line in the middle of it.
def draw_sep(img,location):
    '''Draws a line in img in the middle of the gap discovered at location. Note that
    this doesn't draw the line in location, but draws it at the middle of a gap_box
    starting at location.
    :param img: A PIL.Image file
    :param location: A tuple(x,y) which is a pixel location in the image
    '''
    # First lets bring in all of our drawing code
    from PIL import ImageDraw
    drawing_object=ImageDraw.Draw(img)
    # next, lets decide what the middle means in terms of coordinates in the image
    x1=location[0]+int(gap_box[2]/2)
    # and our x2 is just the same thing, since this is a one pixel vertical line
    x2=x1
    # our starting y coordinate is just the y coordinate which was passed in, the top of the box
    y1=location[1]
    # but we want our final y coordinate to be the bottom of the box
    y2=y1+gap_box[3]
    drawing_object.rectangle((x1,y1,x2,y2), fill = 'black', outline ='black')
    # and we don't have anything we need to return from this, because we modified the image




# iterate through each pixel in the image, check if there is a gap, then insert a line if there is.
def process_image(img):
    '''Takes in an image of text and adds black vertical bars to break up columns
    :param img: A PIL.Image file
    :return: A modified PIL.Image file
    '''
    # we'll start with a familiar iteration process
    for x in range(img.width):
        for y in range(img.height):
            # check if there is a gap at this point
            if (gap_check(img, (x,y))):
                # then update image to one which has a separator drawn on it
                draw_sep(img, (x,y))
    # and for good measure we'll return the image we modified
    return img

# Lets read in our test image and convert it through binarization
i=Image.open("readonly/two_col.png").convert("L")
i=process_image(i)
display(i)


# several ways we might try and control this.
# Lets see how this new image works when run through the kraken layout engine
display(show_boxes(i))
```

---

## Comparing Image Data Structures

1. reads an image and converts it into greyscale.

```py
# import the open cv package cv2
import cv2 as cv
# oad the floyd.jpg image
img = cv.imread('readonly/floyd.jpg')
# convert it to grayscale
gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)

import inspect
inspect.getmro(type(gray))
# [numpy/ndarray, object]
```


```py
gray
```

![Screen Shot 2020-08-26 at 12.02.59](https://i.imgur.com/iLcyVNx.png)


```py
# The array is shown here as a list of lists, where the inner lists are filled with integers.
# The dtype=uint8 definition indicates that each of the items in an array is an 8 bit unsigned
# integer, which is very common for black and white images.
# this is a pixel by pixel definition of the image.
#
# The display package doesn't know what to do with this image.
# convert it into a PIL object to render it in the browser.
from PIL import Image
# "L" is just an array of luminance values in unsigned integers
image = Image.fromarray(gray, "L")
display(image)
```

![Screen Shot 2020-08-26 at 12.06.23](https://i.imgur.com/JjFicQA.png)


```py
# Numpy arrays are multidimensional.
# For instance, define an array in a single dimension:
import numpy as np
single_dim = np.array([25, 50 , 25, 10, 10])

# In an image, this is analagous to a single row of 5 pixels each in grayscale.
# But actually, all imaging libraries tend to expect at least two dimensions, width and heigh
# if put the single_dim inside of another array, this would be a two dimensional array with element in the height direction, and five in the width direction
double_dim = np.array([single_dim])

double_dim
display(Image.fromarray(double_dim, "L"))
#  -----
# just a little line. Five pixels in a row to be exact
```

![Screen Shot 2020-08-26 at 12.10.37](https://i.imgur.com/S5GMR7N.png)


```py
# numpy library attribute: shape: to see how many dimensions big an array is.
# The shape attribute returns a tuple that shows the height and width of the image
double_dim.shape  # (1,5)
img.shape         # (416, 416, 3)
# three dimensions! That's because it has a width, a height, and color depth.
```


```py
first_pixel=img[0][0]
first_pixel
```

![Screen Shot 2020-08-26 at 12.14.43](https://i.imgur.com/7cRhV6N.png)


```py
print("Original image")
print(gray)

print("New image")
# to represent that as a one dimensional image, just call reshape
# reshape takes the image as the first parameter, and a new shape as the second
image1d=np.reshape( gray, (1, gray.shape[0]*gray.shape[1]) )
print(image1d)
```

![Screen Shot 2020-08-26 at 12.15.28](https://i.imgur.com/I79qQ4z.png)


```py
# look for gaps in an image so
# that we could draw lines to feed into kraken

import cv2 as cv
img = cv.imread('readonly/two_col.png')

# convert it to grayscale using the cvtColor image
gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)


# [2:4]
# the sublist of numbers at position 2 through 4 inclusive
# 2:4,1:3]
# rows 2, and 3, and columns 1, and 2.

gray[2:4,1:3]
```

![Screen Shot 2020-08-26 at 12.21.54](https://i.imgur.com/qJR8Rt9.png)


```py
# all white.
# use this as a "window" and move it around image.

# count_nonzero(), returns the number of entries in the matrix which are not zero.
np.count_nonzero(gray[2:4,1:3])
# 4
```


```py
# change pixels

white_matrix=np.full((12,12),255, dtype=np.uint8)

display(Image.fromarray(white_matrix,"L"))
white_matrix
```
![Screen Shot 2020-08-26 at 12.24.42](https://i.imgur.com/k8KKB7W.png)


```py
# color a column to be black
white_matrix[:,6]=np.full((1,12),0, dtype=np.uint8)

display(Image.fromarray(white_matrix,"L"))
white_matrix
```

![Screen Shot 2020-08-26 at 12.25.23](https://i.imgur.com/6vE9JeD.png)


---

## OpenCV


OpenCV comes with trained models for detecting faces, eyes, and smiles


## detect face

```py
import cv2 as cv
face_cascade = cv.CascadeClassifier('readonly/haarcascade_frontalface_default.xml')
eye_cascade = cv.CascadeClassifier('readonly/haarcascade_eye.xml')

img = cv.imread('readonly/floyd.jpg')
# convert it to grayscale using the cvtColor image
gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)


# to use the face_cascade classifier
# use the detectMultiScale() function.
# returns a list of objects as rectangles. The first parameter is an ndarray of the image.
faces = face_cascade.detectMultiScale(gray)

# print those faces out to the screen
faces
```

![Screen Shot 2020-08-26 at 12.30.03](https://i.imgur.com/DoMIHnX.png)

```py
faces.tolist()[0]
```

![Screen Shot 2020-08-26 at 12.31.48](https://i.imgur.com/U8lCcYt.png)

```py
# (x,y,w,h)
# upper left hand point for the image
# the width and height represent the bounding box.


from PIL import Image
from PIL import ImageDraw

# create a PIL image object
pil_img=Image.fromarray(gray,mode="L")
drawing=ImageDraw.Draw(pil_img)

# pull the rectangle out of the faces object
rec=faces.tolist()[0]

# Now we just draw a rectangle around the bounds
drawing.rectangle(rec, outline="white")

# And display
display(pil_img)
```
![Screen Shot 2020-08-26 at 12.33.37](https://i.imgur.com/4DbiF6N.png)


```py
# OpenCV is return the coordinates as (x,y,w,h)
# PIL.ImageDraw is looking for (x1,y1,x2,y2).

pil_img=Image.fromarray(gray,mode="L")
drawing=ImageDraw.Draw(pil_img)

# And draw the new box
drawing.rectangle((rec[0],rec[1],rec[0]+rec[2],rec[1]+rec[3]), outline="white")
# And display
display(pil_img)
```

![Screen Shot 2020-08-26 at 12.36.39](https://i.imgur.com/0lEZI25.png)

---

## second

```py
import cv2 as cv

img = cv.imread('readonly/msi_recruitment.gif')
display(Image.fromarray(img))       # error gif.


# open this in PIL and then save it as a png, then open that in open cv.
pil_img=Image.open('readonly/msi_recruitment.gif')
open_cv_version=pil_img.convert("L") # convert to greyscale for opencv, and get the bytestream
open_cv_version.save("msi_recruitment.png") # write that to a file


# open again
cv_img=cv.imread('msi_recruitment.png')

# detect faces in that image
faces = face_cascade.detectMultiScale(cv_img)

# Now, we still have our PIL color version in a gif
pil_img=Image.open('readonly/msi_recruitment.gif')
# Set our drawing context
drawing=ImageDraw.Draw(pil_img)

# For each item in faces, lets surround it with a red box
for x,y,w,h in faces:
    drawing.rectangle((x,y,x+w,y+h), outline="white")
display(pil_img)
```

![Screen Shot 2020-08-26 at 12.49.20](https://i.imgur.com/JTWy94p.png)

```py
pil_img.mode
# "P"

pil_img = Image.open('readonly/msi_recruitment.gif')
pil_img = pil_img.convert("RGB")
pil_img.mode
# "RBG"

drawing=ImageDraw.Draw(pil_img)
for x,y,w,h in faces:
    drawing.rectangle((x,y,x+w,y+h), outline="white")
display(pil_img)
```

![Screen Shot 2020-08-26 at 12.53.48](https://i.imgur.com/kNEf1pH.png)

---

## improve

```py
# There are a few ways we could try and improve this, and really, it requires a lot of
# experimentation to find good values for a given image. First, lets create a function
# which will plot rectanges for us over the image
def show_rects(faces):
    # read gif and convert it
    pil_img=Image.open('readonly/msi_recruitment.gif').convert("RGB")
    drawing=ImageDraw.Draw(pil_img)
    for x,y,w,h in faces:
        drawing.rectangle((x,y,x+w,y+h), outline="white")
    display(pil_img)



cv_img_bin=cv.threshold(img, 120, 255, cv.THRESH_BINARY)[1]
# returns a list, we want the second value
# Now do the actual face detection
faces = face_cascade.detectMultiScale(cv_img_bin)
# Now lets see the results
show_rects(faces)
```


```py
faces = face_cascade.detectMultiScale(cv_img, 1.05)
show_rects(faces)

faces = face_cascade.detectMultiScale(cv_img, 1.15)
show_rects(faces)

faces = face_cascade.detectMultiScale(cv_img, 1.25)
show_rects(faces)
```

![Screen Shot 2020-08-26 at 12.58.57](https://i.imgur.com/otgbPYn.png)



```py
# compare the speed
%timeit face_cascade.detectMultiScale(cv_img,1.05)  # 117ms
%timeit face_cascade.detectMultiScale(cv_img,1.15)  # 45.6ms
```


---


## More Jupyter Widgets


```py
from ipywebrtc import CameraStream, ImageRecorder
help(CameraStream)
```


```python
# get a camera facing the user, can have the audio on or off.
camera = CameraStream.facing_user(audio=False)

# imagerecorder: grab images from the camera stream.
image_recorder = ImageRecorder(stream=camera)

# Now, the docs are a little unclear how to use this within Jupyter, but if we call the
# download() function it will actually store the results of the camera which is hooked up
# in image_recorder.image. Lets try it out

# start capturing data
image_recorder.recording=True
# download the image
image_recorder.download()


type(image_recorder.image)
# ipywidgets.widgets.widget_media.Image



import PIL.Image
import io

# And now lets create a PIL image from the bytes
img = PIL.Image.open(io.BytesIO(image_recorder.image.value))
# And render it to the screen
display(img)
```

![Screen Shot 2020-08-26 at 13.44.47](https://i.imgur.com/f8KtYc6.png)



.
