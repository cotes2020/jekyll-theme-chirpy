<!DOCTYPE html>
<html>
<head>

    <!-- Document Settings -->
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />

    <!-- Base Meta -->
    <!-- dynamically fixing the title for tag/author pages -->



    <title>Deep Q-Network(DQN) êµ¬í˜„</title>
    <meta name="HandheldFriendly" content="True" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <!-- Styles'n'Scripts -->
    <link rel="stylesheet" type="text/css" href="/assets/built/screen.css" />
    <link rel="stylesheet" type="text/css" href="/assets/built/screen.edited.css" />
    <link rel="stylesheet" type="text/css" href="/assets/built/syntax.css" />
    <!-- highlight.js -->
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css">
    <style>.hljs { background: none; }</style>

    <!--[if IE]>
        <style>
            p, ol, ul{
                width: 100%;
            }
            blockquote{
                width: 100%;
            }
        </style>
    <![endif]-->
    
    <!-- This tag outputs SEO meta+structured data and other important settings -->
    <meta name="description" content="Beanie & Kaze's tech blog" />
    <link rel="shortcut icon" href="http://localhost:4000/assets/img/favicons/favicon.png" type="image/png" />
    <link rel="canonical" href="http://localhost:4000/Implement-DQN" />
    <meta name="referrer" content="no-referrer-when-downgrade" />

    <meta name="google-site-verification" content="X86eN2H5lW1jy6i7OLmOjBAyCf4N8PPVT0sBdIH57LE" />

     <!--title below is coming from _includes/dynamic_title-->
    <meta property="og:site_name" content="Beanie in the wind" />
    <meta property="og:type" content="website" />
    <meta property="og:title" content="Deep Q-Network(DQN) êµ¬í˜„" />
    <meta property="og:description" content="Â  DQN ì´ë€? Â  ì´ì „ì— (Reinforcement learning) Value Function Approximation í¬ìŠ¤íŒ…ì—ì„œ Value function approximationì— ëŒ€í•˜ì—¬ ë‹¤ë£¨ì—ˆë‹¤. ìš”ì•½í•˜ë©´ ê°•í™”í•™ìŠµì—ì„œ ê°„ë‹¨í•œ table í˜•íƒœë¡œ í•™ìŠµì„ í•˜ê²Œ ë˜ë©´ í•™ìŠµì´ ê·¹ë„ë¡œ ëŠë ¤ì§€ëŠ” ë¬¸ì œê°€ ìˆì–´ value functionì„ ë‹¤ì–‘í•˜ê²Œ ê·¼ì‚¬í•˜ì—¬ í™œìš©í•œë‹¤. ì´ëŸ¬í•œ approximatorë¡œ Neural Networkë¥¼ ì‚¬ìš©í•  ìˆ˜ë„ ìˆë‹¤. ì´ë²ˆ ê¸€ì—ì„œ ì†Œê°œí•  Deep Q-Networks(DQN)ì€ Q-learning ì•Œê³ ë¦¬ì¦˜ì˜ Q(Action-value) í•¨ìˆ˜ë¥¼" />
    <meta property="og:url" content="http://localhost:4000/Implement-DQN" />
    <meta property="og:image" content="http://localhost:4000/assets/img/post_images/ai_cover.jpg" />
    <meta property="article:publisher" content="https://www.facebook.com/false" />
    <meta property="article:author" content="https://www.facebook.com/false" />
    <meta property="article:published_time" content="2022-05-16T13:02:00+09:00" />
    <meta property="article:modified_time" content="2022-05-16T13:02:00+09:00" />
    <meta property="article:tag" content="Rl" />
    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:title" content="Deep Q-Network(DQN) êµ¬í˜„" />
    <meta name="twitter:description" content="Â  DQN ì´ë€? Â  ì´ì „ì— (Reinforcement learning) Value Function Approximation í¬ìŠ¤íŒ…ì—ì„œ Value function approximationì— ëŒ€í•˜ì—¬ ë‹¤ë£¨ì—ˆë‹¤. ìš”ì•½í•˜ë©´ ê°•í™”í•™ìŠµì—ì„œ ê°„ë‹¨í•œ table í˜•íƒœë¡œ í•™ìŠµì„ í•˜ê²Œ ë˜ë©´ í•™ìŠµì´ ê·¹ë„ë¡œ ëŠë ¤ì§€ëŠ” ë¬¸ì œê°€ ìˆì–´ value functionì„ ë‹¤ì–‘í•˜ê²Œ ê·¼ì‚¬í•˜ì—¬ í™œìš©í•œë‹¤. ì´ëŸ¬í•œ approximatorë¡œ Neural Networkë¥¼ ì‚¬ìš©í•  ìˆ˜ë„ ìˆë‹¤. ì´ë²ˆ ê¸€ì—ì„œ ì†Œê°œí•  Deep Q-Networks(DQN)ì€ Q-learning ì•Œê³ ë¦¬ì¦˜ì˜ Q(Action-value) í•¨ìˆ˜ë¥¼" />
    <meta name="twitter:url" content="http://localhost:4000/" />
    <meta name="twitter:image" content="http://localhost:4000/assets/img/post_images/ai_cover.jpg" />
    <meta name="twitter:label1" content="Written by" />
    <meta name="twitter:data1" content="Beanie in the wind" />
    <meta name="twitter:label2" content="Filed under" />
    <meta name="twitter:data2" content="Rl" />
    <meta name="twitter:site" content="@false" />
    <meta name="twitter:creator" content="@false" />
    <meta property="og:image:width" content="1400" />
    <meta property="og:image:height" content="933" />
    <script src="https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js"></script>
    <script>mermaid.initialize({startOnLoad:true});</script>
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
        tex2jax: {
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
            inlineMath: [['$','$']]
        }
        });
    </script>
    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
    <meta http-equiv="cache-control" content="max-age=0" />
    <meta http-equiv="cache-control" content="no-cache" />
    <meta http-equiv="expires" content="0" />
    <meta http-equiv="expires" content="Tue, 01 Jan 1980 1:00:00 GMT" />
    <meta http-equiv="pragma" content="no-cache" />
    <script type="application/ld+json">
{
    "@context": "https://schema.org",
    "@type": "Website",
    "publisher": {
        "@type": "Organization",
        "name": "Beanie in the wind",
        "logo": "http://localhost:4000/assets/img/favicons/logo.png"
    },
    "url": "http://localhost:4000/Implement-DQN",
    "image": {
        "@type": "ImageObject",
        "url": "http://localhost:4000/assets/img/post_images/ai_cover.jpg",
        "width": 2000,
        "height": 666
    },
    "mainEntityOfPage": {
        "@type": "WebPage",
        "@id": "http://localhost:4000/Implement-DQN"
    },
    "description": "Â  DQN ì´ë€? Â  ì´ì „ì— (Reinforcement learning) Value Function Approximation í¬ìŠ¤íŒ…ì—ì„œ Value function approximationì— ëŒ€í•˜ì—¬ ë‹¤ë£¨ì—ˆë‹¤. ìš”ì•½í•˜ë©´ ê°•í™”í•™ìŠµì—ì„œ ê°„ë‹¨í•œ table í˜•íƒœë¡œ í•™ìŠµì„ í•˜ê²Œ ë˜ë©´ í•™ìŠµì´ ê·¹ë„ë¡œ ëŠë ¤ì§€ëŠ” ë¬¸ì œê°€ ìˆì–´ value functionì„ ë‹¤ì–‘í•˜ê²Œ ê·¼ì‚¬í•˜ì—¬ í™œìš©í•œë‹¤. ì´ëŸ¬í•œ approximatorë¡œ Neural Networkë¥¼ ì‚¬ìš©í•  ìˆ˜ë„ ìˆë‹¤. ì´ë²ˆ ê¸€ì—ì„œ ì†Œê°œí•  Deep Q-Networks(DQN)ì€ Q-learning ì•Œê³ ë¦¬ì¦˜ì˜ Q(Action-value) í•¨ìˆ˜ë¥¼"
}
    </script>

    <!-- <script type="text/javascript" src="https://demo.ghost.io/public/ghost-sdk.min.js?v=724281a32e"></script>
    <script type="text/javascript">
    ghost.init({
    	clientId: "ghost-frontend",
    	clientSecret: "f84a07a72b17"
    });
    </script> -->

    <meta name="generator" content="Jekyll 3.6.2" />
    <link rel="alternate" type="application/rss+xml" title="Deep Q-Network(DQN) êµ¬í˜„" href="/feed.xml" />



</head>
<body class="post-template">

    <div class="site-wrapper">
        <!-- All the main content gets inserted here, index.hbs, post.hbs, etc -->
        <!-- default -->

<!-- The tag above means: insert everything in this file
into the {body} of the default.hbs template -->

<header class="site-header outer">
    <div class="inner">
        <nav class="site-nav">
    <div class="site-nav-left">
        
            
                <a class="site-nav-logo" href="http://localhost:4000/"><img src="/assets/img/favicons/logo.png" alt="Beanie in the wind" /></a>
            
        
        
            <ul class="nav" role="menu">
    <li class="nav-home" role="menuitem"><a href="/">Home</a></li>
    <li class="nav-about" role="menuitem"><a href="/about/">About</a></li>
    <li class="nav-getting-started" role="menuitem"><a href="/tag/Catty/">Catty</a></li>
</ul>

        
    </div>
    <div class="site-nav-right">
        <div class="social-links">
            
            
        </div>
        
    </div>
</nav>

    </div>
</header>

<!-- Everything inside the #post tags pulls data from the post -->
<!-- #post -->

<main id="site-main" class="site-main outer" role="main">
    <div class="inner">

        <article class="post-full  tag-rl tag-coding post ">

            <header class="post-full-header">
                <section class="post-full-meta">
                    <time class="post-full-meta-date" datetime="16 May 2022">16 May 2022</time>
                    
                        <span class="date-divider">/</span>
                        
                            
                               <a href='/tag/rl/'>RL</a>,
                            
                        
                            
                               <a href='/tag/coding/'>CODING</a>
                            
                        
                    
                </section>
                <h1 class="post-full-title">Deep Q-Network(DQN) êµ¬í˜„</h1>
            </header>

            
            <figure class="post-full-image" style="background-image: url(/assets/img/post_images/ai_cover.jpg)">
            </figure>
            

            <section class="post-full-content">
                <div class="kg-card-markdown">
                    <p>Â </p>
<h2 id="dqn-ì´ë€">DQN ì´ë€?</h2>
<p>Â 
ì´ì „ì— <a href="">(Reinforcement learning) Value Function Approximation í¬ìŠ¤íŒ…</a>ì—ì„œ Value function approximationì— ëŒ€í•˜ì—¬ ë‹¤ë£¨ì—ˆë‹¤. ìš”ì•½í•˜ë©´ ê°•í™”í•™ìŠµì—ì„œ ê°„ë‹¨í•œ table í˜•íƒœë¡œ í•™ìŠµì„ í•˜ê²Œ ë˜ë©´ í•™ìŠµì´ ê·¹ë„ë¡œ ëŠë ¤ì§€ëŠ” ë¬¸ì œê°€ ìˆì–´ value functionì„ ë‹¤ì–‘í•˜ê²Œ ê·¼ì‚¬í•˜ì—¬ í™œìš©í•œë‹¤.</p>

<p>ì´ëŸ¬í•œ approximatorë¡œ Neural Networkë¥¼ ì‚¬ìš©í•  ìˆ˜ë„ ìˆë‹¤. ì´ë²ˆ ê¸€ì—ì„œ ì†Œê°œí•  Deep Q-Networks(DQN)ì€ Q-learning ì•Œê³ ë¦¬ì¦˜ì˜ Q(Action-value) í•¨ìˆ˜ë¥¼ ë”¥ëŸ¬ë‹ìœ¼ë¡œ ê·¼ì‚¬í•˜ëŠ” ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ, DeepMindì—ì„œ ë°œí‘œí•œ <a href="https://arxiv.org/pdf/1312.5602.pdf"><code class="language-plaintext highlighter-rouge">Playing Atari with Deep Reinforcement</code></a> ë¼ëŠ” ì—°êµ¬ì—ì„œ ì œì•ˆë˜ì—ˆë‹¤.</p>

<p>ì´ DQN ë…¼ë¬¸ì—ì„œëŠ” raw pixelì„ inputìœ¼ë¡œ ë°›ì•„, value function(â‰ˆfuture rewards)ë¥¼ outputìœ¼ë¡œ ë°˜í™˜í•˜ëŠ” Q-Learningì˜ parameterë¥¼ í•™ìŠµí•˜ëŠ” Convolutional Neural Network(CNN)ì„ ì‚¬ìš©í•˜ì˜€ë‹¤. ì¦‰, ê³ ì°¨ì›ì˜ sensory inputì„ í†µí•´ control policiesë¥¼ ë‹¤ì´ë ‰íŠ¸ë¡œ í•™ìŠµí•˜ëŠ” Deep learning modelì´ë¼ê³  ë³¼ ìˆ˜ ìˆë‹¤.</p>

<p>ê·¸ë ‡ë‹¤ë©´ ì´ì „ì—ëŠ” ì™œ ê°•í™”í•™ìŠµì— ë”¥ëŸ¬ë‹ì„ í™œìš©í•˜ì§€ ëª»í–ˆì„ê¹Œ? ì‚¬ì‹¤ ë”¥ëŸ¬ë‹ê³¼ ê°•í™”í•™ìŠµì´ ê³ ì°¨ì›ì˜ ë°ì´í„°ë¥¼ í™œìš©í•˜ëŠ” ë°©ë²•ì€ ë¬´ì²™ ë‹¤ë¥´ë‹¤. ëª‡ê°€ì§€ ì˜ˆì‹œë¡œ</p>
<ul>
  <li>Deep-Learning ê¸°ë°˜ ë°©ë²•ë“¤ì€ hand-labelled training datasetì„ í•„ìš”ë¡œ í•˜ì§€ë§Œ, Reinforcement Learningì—ì„œëŠ” ì˜¤ë¡œì§€ delayì™€ ë…¸ì´ì¦ˆê°€ í¬í•¨ëœ ìŠ¤ì¹¼ë¼ê°’ì¸ Rewardë§Œì„ í†µí•´ì„œ í•™ìŠµëœë‹¤. ë”ìš±ì´ë‚˜ ê·¸ reward ì¡°ì°¨ sparse, noisy, and delayí•œ ì„±ê²©ì„ ê°€ì§„ë‹¤.</li>
  <li>Deep Learningì—ì„œëŠ” data sampleì´ i.i.dí•˜ë‹¤ëŠ” ê°€ì •ì´ ìˆë‹¤. í•˜ì§€ë§Œ, Reinforcement Learningì˜ ê²½ìš° í˜„ì¬ì˜ stateê°€ ì–´ë””ì¸ ì§€ì— ë”°ë¼ ê°€ëŠ¥í•œ ë‹¤ìŒ stateê°€ ê²°ì •ëœë‹¤. ì¦‰, ë…ë¦½ì ì´ì§€ ì•Šê³  ì¢…ì†ì ì´ë©°, stateê°„ì˜ correlation(ìƒê´€ê´€ê³„)ë˜í•œ í¬ë‹¤.</li>
  <li>ì—ì´ì „íŠ¸ê°€ í•™ìŠµí•¨ì— ë”°ë¼ policyê°€ ë‹¬ë¼ì§€ë©´ì„œ, í•™ìŠµ ë°ì´í„°ì˜ ë¶„ì‚°(distribution) ìì²´ë„ ì‹œê°„ì— ë”°ë¼ ë³€í•œë‹¤. ë°˜ë©´ ë”¥ëŸ¬ë‹ì€ ê³ ì •ëœ ê¸°ë³¸ ë¶„ì‚°(fixed underlying distribution)ì„ ê°€ì •í•œë‹¤.</li>
</ul>

<p>ì´ëŸ¬í•œ ê°•í™”í•™ìŠµì— ì´ìœ ë¡œ ë”¥ëŸ¬ë‹ ê¸°ë²•ì„ ì´ì „ì—ëŠ” ë°”ë¡œ ì ìš©í•˜ì§€ ëª»í•˜ì˜€ë‹¤.</p>

<p><code class="language-plaintext highlighter-rouge">Playing Atari with Deep Reinforcement</code> ë…¼ë¬¸ë„ ì˜ˆì™¸ì—†ì´ ì´ëŸ¬í•œ ë¬¸ì œì— ì§ë©´í–ˆëŠ”ë°, ë…¼ë¬¸ì—ì„œëŠ” ì´ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•˜ì—¬ <strong>Experience replay</strong> ì™€ <strong>Target network</strong> ë¼ëŠ” ë°©ë²•ì„ ì œì•ˆí•˜ì˜€ë‹¤. ì´ ë‘ íŠ¹ì§•ì ì¸ ë°©ë²•ì„ í†µí•˜ì—¬ ì„±ê³µì ìœ¼ë¡œ ë”¥ëŸ¬ë‹ì„ ê°•í™”í•™ìŠµì— ì ìš©í•˜ì—¬ ê³ ì°¨ì› ë°ì´í„°ë¥¼ ì²˜ë¦¬í•  ìˆ˜ ìˆê²Œ ë˜ì—ˆë‹¤.</p>

<h3 id="experience-replay">Experience replay</h3>
<p>ë“¤ì–´ì˜¤ëŠ” ì…ë ¥ì„ ìˆœì„œëŒ€ë¡œ ì‚¬ìš©í•˜ë©´ ë°ì´í„° ê°„ì˜ ì—°ê´€ì„±ì´ ë„ˆë¬´ ì»¤ì§€ê²Œ ëœë‹¤. ë”°ë¼ì„œ ìµœê·¼ nê°œì˜ ë°ì´í„°ë¥¼ ê³„ì†í•´ì„œ ì €ì¥í•˜ê³ , ë„¤íŠ¸ì›Œí¬ë¥¼ í•™ìŠµí•  ë•ŒëŠ” ì €ì¥í•œ ë°ì´í„° ì¤‘ ëª‡ê°œë¥¼ ë¬´ì‘ìœ„ë¡œ ìƒ˜í”Œí•˜ì—¬ ì‚¬ìš©í•œë‹¤.</p>

<h3 id="target-network">Target network</h3>
<p>Target network ì„¤ëª…ì€ <a href="https://jsideas.net/dqn/">https://jsideas.net/dqn/</a>ì˜ ë‹¹ë‚˜ê·€ ì˜ˆì‹œê°€ ì´í•´í•˜ê¸° ì¢‹ì•˜ë‹¤. ì´ ë¸”ë¡œê·¸ì˜ ì„¤ëª…ì„ ì°¨ìš©í•˜ë©´</p>

<blockquote>
  <p>ì¼ë°˜ì ì¸ Q Learningì€ ë‹¹ë‚˜ê·€ ë’¤ì— ì˜¬ë¼íƒ€ ë‚šì‹œëŒ€ë¡œ ë‹¹ê·¼ì„ ë“œë¦¬ìš°ê³  ë‹¹ë‚˜ê·€ê°€ ê³§ê²Œ ê±·ê¸°ë¥¼ ë°”ë¼ëŠ” ê²ƒê³¼ ê°™ë‹¤. ë‹¹ê·¼ì„ ë“  ì†ì„ ê³§ê²Œë§Œ ìœ ì§€í•˜ë©´ ë‹¹ë‚˜ê·€ê°€ ì§ì§„í•  ê²ƒì´ë¼ê³  ìƒê°í•˜ì§€ë§Œ, ì‹¤ì œë¡œëŠ” ì˜ ì•ˆëœë‹¤. ë‹¹ë‚˜ê·€ì™€ ì‚¬ëŒ, ê·¸ë¦¬ê³  ë‚šì‹œëŒ€ì™€ ë‹¹ê·¼ì´ ëª¨ë‘ ì—°ê²°ë˜ì–´ ìˆê¸°ì—, ë‹¹ë‚˜ê·€ê°€ ì›€ì§ì´ë©´ ì˜¬ë¼íƒ„ ì‚¬ëŒë„ í”ë“¤ë¦¬ê³  ê·¸ì— ë”°ë¼ ë‹¹ê·¼ë„ í”ë“¤ë¦°ë‹¤. ê²°êµ­ ì˜ìƒì—ì„œì²˜ëŸ¼ ë‹¹ë‚˜ê·€ëŠ” ì§ì„ ìœ¼ë¡œ ì´ë™í•˜ëŠ”ë° ì‹¤íŒ¨í•œë‹¤.</p>
</blockquote>

<blockquote>
  <p>ë‹¹ê·¼ì˜ ìœ„ì¹˜ë¥¼ Q í•¨ìˆ˜ì˜ íƒ€ê²Ÿ $(r+max_{aâ€™}Q(s^{â€˜}, a^{â€˜}))$ ìœ¼ë¡œ, ë‹¹ë‚˜ê·€ì˜ ì›€ì§ì„ì„ ì¶”ì •ì¹˜(Q)ë¡œ ëŒ€ì…í•´ë³´ë©´ ëœë‹¤. íƒ€ê²Ÿê³¼ ì¶”ì •ì¹˜ì˜ ì˜¤ì°¨ë¥¼ ì¤„ì—¬ì•¼í•˜ëŠ”ë°, Qì˜ ë³€í™”ì— ë”°ë¼ íƒ€ê²Ÿê³¼ ì¶”ì •ì¹˜ê°€ ëª¨ë‘ í•¨ê»˜ ë³€í™”í•˜ë©´ ì•ˆì •ì ì¸ í•™ìŠµ(ì´ë™)ì´ ì–´ë ¤ì›Œì§„ë‹¤.</p>
</blockquote>

<blockquote>
  <p>DQNì—ì„œëŠ” ë‹¹ë‚˜ê·€ì™€ ë‹¹ê·¼ì„ ë¶„ë¦¬ì‹œí‚¤ëŠ” Fixed Q Targets ë°©ë²•ì„ ì‚¬ìš©í•´ì„œ ë¬¸ì œë¥¼ í•´ê²°í•œë‹¤. Qí•¨ìˆ˜ë¥¼ ì¶”ì •í•˜ëŠ” ë„¤íŠ¸ì›Œí¬(local network)ì™€ Targetì„ ì„¤ì •í•˜ëŠ”ë° ì‚¬ìš©í•˜ëŠ” ë„¤íŠ¸ì›Œí¬(target network)ë¡œ ì¶”ì •ê³¼ í‰ê°€ë¥¼ ë¶„ë¦¬í•œë‹¤. ë‹¹ë‚˜ê·€ ë“±ì—ì„œ ë‚´ë ¤ì„œ ë‚šì‹œëŒ€ë¥¼ ë“œë¦¬ìš°ë©´, ë‹¹ê·¼ì˜ ìœ„ì¹˜ëŠ” ë”ì´ìƒ ë‹¹ë‚˜ê·€ì˜ ì›€ì§ì„ì— ì˜í–¥ì„ ë°›ì§€ ì•ŠëŠ”ë‹¤.</p>
</blockquote>

<blockquote>
  <p>ê·¸ë¦¬ê³  target networkì˜ ì—…ë°ì´íŠ¸ ì£¼ê¸°ë¥¼ local networkë³´ë‹¤ ë” ëŠë¦¬ê²Œ ë§Œë“¦ìœ¼ë¡œì¨ ëª©í‘œê°€ ìì£¼ íœ˜ì²­ì´ì§€ ì•Šë„ë¡ í•œë‹¤. DQN êµ¬í˜„ì—ì„œëŠ” local networkê°€ 4ë²ˆ ì—…ë°ì´íŠ¸ë  ë•Œ í•œë²ˆì”© target networkì˜ íŒŒë¼ë¯¸í„°ë¥¼ local networkì˜ íŒŒë¼ë¯¸í„°ë¥¼ ì‚¬ìš©í•´ soft updateí•œë‹¤.</p>
</blockquote>

<p>Â </p>
<h2 id="dqn-êµ¬í˜„">DQN êµ¬í˜„</h2>
<p>Â </p>

<h3 id="environment">Environment</h3>
<p>ë¨¼ì €, ì´ë²ˆ DQN êµ¬í˜„ì€ ì œê³µë°›ì€ 2ê°œì˜ GridWorld í™˜ê²½ì„ ê¸°ë°˜ìœ¼ë¡œ ì§„í–‰í•˜ì˜€ë‹¤.</p>

<p>ë¨¼ì € ì²«ë²ˆì§¸ GridWorldëŠ” ê·¸ë¦¼ê³¼ ê°™ë‹¤.</p>

<div style="text-align: left">
  <img src="/assets/img/post_images/dqn4.png" width="50%" />
</div>

<p>ê·¸ë¦¼ì—ì„œ ë³¼ ìˆ˜ ìˆë“¯ì´ ì´ í™˜ê²½ì€ ë…¸ë€ ë™ê·¸ë¼ë¯¸, ë¹¨ê°„ ë„¤ëª¨, ë…¹ìƒ‰ ë„¤ëª¨ë¡œ êµ¬ì„±ë˜ì–´ ìˆë‹¤. ê°ê°ì„ ì‚´í´ë³´ë©´,</p>

<ul>
  <li>ë…¸ë€ ë™ê·¸ë¼ë¯¸ : agentì˜ ì›€ì§ì„ì„ ë‚˜íƒ€ë‚¸ë‹¤.</li>
  <li>ë¹¨ê°„ ë„¤ëª¨ : í­íƒ„ì´ ìœ„ì¹˜í•´ ìˆìœ¼ë©° agentê°€ í•´ë‹¹ ìœ„ì¹˜ë¡œ ê°€ë©´ reward -10ì„ ì–»ê³  ë‹¤ì‹œ episodeë¥¼ ì‹œì‘í•œë‹¤.</li>
  <li>ì´ˆë¡ ë„¤ëª¨ : ë³´ë¬¼ì´ ìœ„ì¹˜í•´ ìˆìœ¼ë©° agentê°€ í•´ë‹¹ ìœ„ì¹˜ë¡œ ê°€ë©´ reward 20ì„ ì–»ê³  ë‹¤ì‹œ episodeë¥¼ ì‹œì‘í•œë‹¤.</li>
  <li>ë¹¨ê°„ ë„¤ëª¨, ì´ˆë¡ ë„¤ëª¨ê°€ ì—†ëŠ” ê³µê°„ì„ ë…¸ë€ ë™ê·¸ë¼ë¯¸ê°€ íƒìƒ‰í•  ë•Œë§ˆë‹¤ reward -0.1ì„ ì–»ëŠ”ë‹¤.</li>
</ul>

<p>ë‘ë²ˆì§¸ GridWorldëŠ” ì²«ë²ˆì§¸ GridWorldì— ì£¼í™© ë„¤ëª¨ê°€ ì¶”ê°€ë˜ì—ˆë‹¤.</p>

<div style="text-align: left">
  <img src="/assets/img/post_images/dqn5.png" width="45%" />
</div>

<ul>
  <li>ì£¼í™© ë„¤ëª¨ : ìŒì‹ ìœ„ì¹˜í•´ ìˆìœ¼ë©° agentê°€ í•´ë‹¹ ìœ„ì¹˜ë¡œ ê°€ë©´ reward 10ì„ ì–»ê³  ë‹¤ì‹œ episodeë¥¼ ì‹œì‘í•œë‹¤.</li>
</ul>

<h3 id="dqn-class-êµ¬í˜„">DQN class êµ¬í˜„</h3>

<p>ì´ëŸ¬í•œ í™˜ê²½ì—ì„œ ì˜ ë™ì‘í•  ìˆ˜ ìˆëŠ” DQNì„ êµ¬í˜„í•´ë³´ì.
DQN êµ¬í˜„ì€ <strong>neural network ìƒì„±</strong>, <strong>action ì„ íƒ</strong>, <strong>experience replayë¥¼ ìœ„í•˜ì—¬ ì´ì „ experienceë¥¼ ë©”ëª¨ë¦¬ì— ì €ì¥</strong>, <strong>ë©”ëª¨ë¦¬ì— í¬í•¨ëœ experienceë¥¼ ì´ìš©í•˜ì—¬ í•™ìŠµ</strong>ì˜ ê³¼ì •ìœ¼ë¡œ ë‚˜ëˆ ë³¼ ìˆ˜ ìˆë‹¤.</p>

<ul>
  <li>
    <p><strong>neural network ìƒì„±</strong> (<code class="language-plaintext highlighter-rouge">_construct_network()</code> í•¨ìˆ˜)</p>

    <div style="text-align: left">
  <img src="/assets/img/post_images/dqn3.jpeg" width="80%" />
  </div>

    <p>ì´ DQN ëª¨ë¸ì—ì„œ êµ¬í˜„í•œ neural networkëŠ” ìœ„ ë‹¤ì´ì–´ê·¸ë¨ê³¼ ë¹„ìŠ·í•˜ë‹¤. ë¨¼ì € input layerì—ì„œ n_features sizeì˜ ì…ë ¥ì„ ë°›ê³  24 í¬ê¸°ë¡œ ì¶œë ¥ì„ í•œë‹¤. ì´ ë•Œ, activation í•¨ìˆ˜ë¡œ relu í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì˜€ë‹¤. ë˜í•œ Hidden layerì—ì„œëŠ” ì´ì „ ë ˆì´ì–´ì˜ ì¶œë ¥ì„ ì¸í’‹ìœ¼ë¡œ ë°›ì•„ 24 í¬ê¸°ë¡œ ì¶œë ¥ì„ í•œë‹¤. ì´ ë•Œë„ ë§ˆì°¬ê°€ì§€ë¡œ activation í•¨ìˆ˜ë¡œ reluë¥¼ ì‚¬ìš©í•˜ì˜€ë‹¤. ë§ˆì§€ë§‰ output layerì—ì„œëŠ” n_actions í¬ê¸°ë¡œ ì¶œë ¥ì„ í•˜ê³  ì´ ë•Œ, activation í•¨ìˆ˜ë¥¼ linearë¡œ ì„¤ì •í•˜ì˜€ë‹¤. ì´ë ‡ê²Œ êµ¬í˜„í•œ ëª¨ë¸ì˜ ì½”ë“œëŠ” ì•„ë˜ì™€ ê°™ë‹¤.</p>

    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>

  <span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">24</span><span class="p">,</span> <span class="n">input_dim</span><span class="o">=</span><span class="bp">self</span><span class="p">.</span><span class="n">n_features</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">))</span>
  <span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">24</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">))</span>
  <span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">n_actions</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'linear'</span><span class="p">))</span>
  <span class="n">model</span><span class="p">.</span><span class="nb">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s">'mse'</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">Adam</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="bp">self</span><span class="p">.</span><span class="n">learning_rate</span><span class="p">))</span>
</code></pre></div>    </div>

    <p>ì´ ëª¨ë¸ì— n_features í¬ê¸°ì˜ state ë²¡í„°ê°€ ë“¤ì–´ì˜¤ë©´ ëª¨ë¸ì˜ predictionìœ¼ë¡œ ì–»ì€ ì˜ˆì¸¡ëœ reward ê°’ê³¼ true reward ê°’ì˜ ì—ëŸ¬ê°€ ì‘ì•„ì§€ë„ë¡ ë‚´ë¶€ weight ê°’ì„ ì¡°ì •í•œë‹¤. ì´ë¥¼ ê³„ì† ë°˜ë³µí•˜ë‹¤ë³´ë©´ ì˜ˆì¸¡ëœ rewardê°€ true rewardì™€ ê°™ì•„ì§€ëŠ” ë°©í–¥ìœ¼ë¡œ (ìµœì  policyë¥¼ ì°¾ëŠ” ë°©í–¥ìœ¼ë¡œ) í•™ìŠµë˜ê²Œ ëœë‹¤.</p>

    <p>ì¢€ ë” êµ¬ì²´ì ìœ¼ë¡œ í•™ìŠµ ê³¼ì •ì„ <code class="language-plaintext highlighter-rouge">model.fit()</code>ê³¼ <code class="language-plaintext highlighter-rouge">model.predict()</code> í•¨ìˆ˜ë¡œ ë‹¤ì‹œ ë‚˜ëˆŒ ìˆ˜ ìˆë‹¤. ê°ê°ì„ ì‚´í´ë³´ë©´,</p>
    <ul>
      <li><code class="language-plaintext highlighter-rouge">model.fit(state, true_reward, epochs=1, verbose)</code>
        <ul>
          <li>ì£¼ì–´ì§„ stateì—ì„œ true rewardë¥¼ ì˜ˆì¸¡í•˜ë„ë¡ í•™ìŠµí•œë‹¤.</li>
        </ul>
      </li>
      <li><code class="language-plaintext highlighter-rouge">model.predict(state)</code>
        <ul>
          <li>unseen inputì— ëŒ€í•˜ì—¬ rewardë¥¼ ì˜ˆì¸¡í•œë‹¤.</li>
        </ul>
      </li>
    </ul>

    <p>ì´ <code class="language-plaintext highlighter-rouge">model.fit()</code>ê³¼ <code class="language-plaintext highlighter-rouge">model.predict()</code>ë¥¼ í•™ìŠµ ê³¼ì •ì—ì„œ í™œìš©í•˜ë©° ìµœì  policyë¥¼ ì°¾ì•„ë‚˜ê°”ë‹¤.</p>
  </li>
  <li><strong>action ì„ íƒ</strong> (<code class="language-plaintext highlighter-rouge">choose_action()</code> í•¨ìˆ˜)
    <ul>
      <li>e_greedy í™•ë¥ ë¡œëŠ” random í•˜ê²Œ actionì„ ì„ íƒí•˜ê³ , 1 - (e-greedy) í™•ë¥ ë¡œëŠ” ëª¨ë¸ì—ì„œ ì˜ˆì¸¡í•œ rewardê°€ ê°€ì¥ í° actionì„ ì„ íƒí•œë‹¤.</li>
    </ul>
  </li>
  <li><strong>experienceë¥¼ ë©”ëª¨ë¦¬ì— ì €ì¥</strong> (<code class="language-plaintext highlighter-rouge">store_transition()</code> í•¨ìˆ˜)
    <ul>
      <li>experience replay ë°©ì‹ìœ¼ë¡œ experienceë¥¼ ì¬í™œìš© ìœ„í•˜ì—¬ í•™ìŠµì„ ë©”ëª¨ë¦¬ì— ì €ì¥í•´ë‘”ë‹¤.</li>
    </ul>
  </li>
  <li><strong>ë©”ëª¨ë¦¬ì˜ experienceë¥¼ ì´ìš©í•˜ì—¬ í•™ìŠµ</strong> (<code class="language-plaintext highlighter-rouge">learn()</code> í•¨ìˆ˜)</li>
</ul>

<p>ì´ ê³¼ì •ì„ í†µí•©í•˜ì—¬ êµ¬í˜„ëœ ì „ì²´ DQN Class ì½”ë“œëŠ” ì•„ë˜ì™€ ê°™ë‹¤.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">deque</span>
<span class="kn">from</span> <span class="nn">keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>
<span class="kn">from</span> <span class="nn">keras.layers</span> <span class="kn">import</span> <span class="n">Dense</span>
<span class="kn">from</span> <span class="nn">keras.optimizers</span> <span class="kn">import</span> <span class="n">Adam</span>

<span class="n">EPISODES</span> <span class="o">=</span> <span class="mi">1000</span>

<span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">DeepQLearning</span><span class="p">:</span>
   <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span>
           <span class="bp">self</span><span class="p">,</span>
           <span class="n">n_actions</span><span class="p">,</span>
           <span class="n">n_features</span><span class="p">,</span>
           <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span>
           <span class="n">discount_factor</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span>
           <span class="n">e_greedy</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span>
           <span class="n">replace_target_iter</span><span class="o">=</span><span class="mi">300</span><span class="p">,</span>
           <span class="n">memory_size</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span>
           <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span>
   <span class="p">):</span>
       <span class="bp">self</span><span class="p">.</span><span class="n">n_actions</span> <span class="o">=</span> <span class="n">n_actions</span>
       <span class="bp">self</span><span class="p">.</span><span class="n">n_features</span> <span class="o">=</span> <span class="n">n_features</span>
       <span class="bp">self</span><span class="p">.</span><span class="n">learning_rate</span> <span class="o">=</span> <span class="n">learning_rate</span>
       <span class="bp">self</span><span class="p">.</span><span class="n">discount_factor</span> <span class="o">=</span> <span class="n">discount_factor</span>
       <span class="bp">self</span><span class="p">.</span><span class="n">memory</span> <span class="o">=</span> <span class="n">deque</span><span class="p">(</span><span class="n">maxlen</span><span class="o">=</span><span class="n">memory_size</span><span class="p">)</span>
       <span class="bp">self</span><span class="p">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>
       <span class="bp">self</span><span class="p">.</span><span class="n">e_greedy</span> <span class="o">=</span> <span class="n">e_greedy</span>
       <span class="bp">self</span><span class="p">.</span><span class="n">replace_target_iter</span> <span class="o">=</span> <span class="n">replace_target_iter</span>
       <span class="bp">self</span><span class="p">.</span><span class="n">model</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">_construct_network</span><span class="p">()</span>

   <span class="k">def</span> <span class="nf">_construct_network</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
       <span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>

       <span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">24</span><span class="p">,</span> <span class="n">input_dim</span><span class="o">=</span><span class="bp">self</span><span class="p">.</span><span class="n">n_features</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">))</span>
       <span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">24</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">))</span>
       <span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">n_actions</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'linear'</span><span class="p">))</span>
       <span class="n">model</span><span class="p">.</span><span class="nb">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s">'mse'</span><span class="p">,</span>
                     <span class="n">optimizer</span><span class="o">=</span><span class="n">Adam</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="bp">self</span><span class="p">.</span><span class="n">learning_rate</span><span class="p">))</span>
       <span class="k">return</span> <span class="n">model</span>

   <span class="k">def</span> <span class="nf">store_transition</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">r</span><span class="p">,</span> <span class="n">next_s</span><span class="p">,</span> <span class="n">t</span><span class="p">):</span>
       <span class="bp">self</span><span class="p">.</span><span class="n">memory</span><span class="p">.</span><span class="n">append</span><span class="p">((</span><span class="n">s</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">r</span><span class="p">,</span> <span class="n">next_s</span><span class="p">,</span> <span class="n">t</span><span class="p">))</span>

   <span class="k">def</span> <span class="nf">choose_action</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
       <span class="c1"># e_greedy í™•ë¥ ë¡œëŠ” random í•˜ê²Œ actionì„ ì„ íƒí•˜ê³ , 1 - (e-greedy) í™•ë¥ ë¡œëŠ” ëª¨ë¸ì—ì„œ ì˜ˆì¸¡í•œ rewardê°€ ê°€ì¥ í° actionì„ ì„ íƒí•œë‹¤.
</span>       <span class="n">state</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">n_features</span><span class="p">])</span>

       <span class="c1"># e_greedy í™•ë¥ ë¡œ random í•˜ê²Œ actionì„ ì„ íƒ
</span>       <span class="k">if</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">rand</span><span class="p">()</span> <span class="o">&lt;=</span> <span class="bp">self</span><span class="p">.</span><span class="n">e_greedy</span><span class="p">:</span>
           <span class="k">return</span> <span class="n">random</span><span class="p">.</span><span class="n">randrange</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">n_actions</span><span class="p">)</span>

       <span class="c1">#  1 - (e-greedy) í™•ë¥ ë¡œ ëª¨ë¸ì„ í†µí•´ ì˜ˆì¸¡í•œ rewardê°€ ê°€ì¥ í° actionì„ ì„ íƒ
</span>       <span class="n">act_values</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
       <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">act_values</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>  <span class="c1"># returns action
</span>
   <span class="k">def</span> <span class="nf">learn</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
       <span class="c1"># ë©”ëª¨ë¦¬ì— ì €ì¥ëœ experienceì—ì„œ batch_sizeë§Œí¼ ëœë¤í•˜ê²Œ ì„ íƒ
</span>       <span class="n">minibatch</span> <span class="o">=</span> <span class="n">random</span><span class="p">.</span><span class="n">sample</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">memory</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">batch_size</span><span class="p">)</span>
       <span class="c1"># ì„ íƒëœ ê°ê°ì˜ experienceì— ëŒ€í•˜ì—¬ ëª¨ë¸ì´ ì‹¤ì œ experienceë¡œ ì–»ì€ reward ë°©í–¥ìœ¼ë¡œ ê°’ì„ ì˜ ì˜ˆì¸¡í•˜ë„ë¡ í•™ìŠµì„ ì§„í–‰
</span>       <span class="k">for</span> <span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">next_state</span><span class="p">,</span> <span class="n">done</span> <span class="ow">in</span> <span class="n">minibatch</span><span class="p">:</span>
           <span class="n">state</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">n_features</span><span class="p">])</span>
           <span class="n">next_state</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">next_state</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">n_features</span><span class="p">])</span>
           <span class="n">target</span> <span class="o">=</span> <span class="n">reward</span>
           <span class="k">if</span> <span class="ow">not</span> <span class="n">done</span><span class="p">:</span>
               <span class="n">target</span> <span class="o">=</span> <span class="p">(</span><span class="n">reward</span> <span class="o">+</span> <span class="bp">self</span><span class="p">.</span><span class="n">discount_factor</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="n">amax</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">next_state</span><span class="p">)[</span><span class="mi">0</span><span class="p">]))</span>
           <span class="n">target_f</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
           <span class="n">target_f</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">action</span><span class="p">]</span> <span class="o">=</span> <span class="n">target</span>
           <span class="bp">self</span><span class="p">.</span><span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">target_f</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</code></pre></div></div>

<p>Â </p>
<h2 id="dqn-class-ì‹¤í–‰">DQN Class ì‹¤í–‰</h2>
<p>Â </p>

<p>ì´ì œ ì´ë ‡ê²Œ êµ¬í˜„í•œ DQN Classë¥¼ í™œìš©í•˜ì—¬ í•™ìŠµì„ ì§„í–‰í•´ë³´ì•˜ë‹¤.
ì´ 300ê°œì˜ episodeì— ëŒ€í•˜ì—¬ DQNì„ í•™ìŠµì‹œí‚¤ê³  average episode returnì„ ê·¸ë ¤ë³´ì•˜ë‹¤.
ì´ ë•Œ, return ê°’ì´ ìƒˆë¡­ê²Œ í•™ìŠµì„ ëŒë¦´ ë•Œ ë§ˆë‹¤ ë‹¬ë¼ì§€ê¸° ë•Œë¬¸ì— 300ê°œì˜ episodeë¡œ í•™ìŠµí•˜ëŠ” ê³¼ì • ì „ì²´ë¥¼ 5ë²ˆ ë°˜ë³µí•´ì„œ episode rewardì˜ min-max, meanë¥¼ ë‚˜ëˆ„ì–´ plotí•˜ì˜€ë‹¤.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="kn">from</span> <span class="nn">env</span> <span class="kn">import</span> <span class="n">Robot_Gridworld</span>
<span class="kn">from</span> <span class="nn">env2</span> <span class="kn">import</span> <span class="n">Robot_Gridworld</span> <span class="k">as</span> <span class="n">Robot_Gridworld2</span>
<span class="kn">from</span> <span class="nn">deep_q_learning</span> <span class="kn">import</span> <span class="n">DeepQLearning</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">deque</span>

<span class="n">return_value</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">gamma</span> <span class="o">=</span> <span class="mf">0.99</span>
<span class="n">episode_return_list</span><span class="o">=</span><span class="p">[]</span>
<span class="k">def</span> <span class="nf">update</span><span class="p">():</span>
   <span class="k">global</span> <span class="n">return_value</span>
   <span class="n">step</span> <span class="o">=</span> <span class="mi">0</span>
   <span class="n">reward_per_episode</span> <span class="o">=</span> <span class="p">[]</span>
   <span class="n">returns</span> <span class="o">=</span> <span class="n">deque</span><span class="p">(</span><span class="n">maxlen</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>

   <span class="k">for</span> <span class="n">episode</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">300</span><span class="p">):</span>

       <span class="n">state</span> <span class="o">=</span> <span class="n">env</span><span class="p">.</span><span class="n">reset</span><span class="p">()</span>
       <span class="n">step_count</span> <span class="o">=</span> <span class="mi">0</span>

       <span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
           <span class="n">return_value</span> <span class="o">=</span> <span class="mi">0</span>
           <span class="n">env</span><span class="p">.</span><span class="n">render</span><span class="p">()</span>
           <span class="n">action</span> <span class="o">=</span> <span class="n">dqn</span><span class="p">.</span><span class="n">choose_action</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
           <span class="n">next_state</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">terminal</span> <span class="o">=</span> <span class="n">env</span><span class="p">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
           <span class="n">return_value</span> <span class="o">=</span> <span class="n">reward</span> <span class="o">+</span> <span class="n">gamma</span> <span class="o">*</span> <span class="n">return_value</span>

           <span class="n">step_count</span> <span class="o">+=</span> <span class="mi">1</span>
           <span class="n">dqn</span><span class="p">.</span><span class="n">store_transition</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">next_state</span><span class="p">,</span> <span class="n">terminal</span><span class="p">)</span>

           <span class="k">if</span> <span class="p">(</span><span class="n">step</span> <span class="o">&gt;</span> <span class="mi">200</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">step</span> <span class="o">%</span> <span class="mi">5</span> <span class="o">==</span> <span class="mi">0</span><span class="p">):</span>
               <span class="n">dqn</span><span class="p">.</span><span class="n">learn</span><span class="p">()</span>
           <span class="n">state</span> <span class="o">=</span> <span class="n">next_state</span>

           <span class="k">if</span> <span class="n">terminal</span> <span class="o">==</span> <span class="bp">True</span><span class="p">:</span>
               <span class="k">print</span><span class="p">(</span><span class="s">" {} End. Total steps : {}</span><span class="se">\n</span><span class="s">"</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">episode</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">step_count</span><span class="p">))</span>
               <span class="k">break</span>

           <span class="n">step</span> <span class="o">+=</span> <span class="mi">1</span>

       <span class="n">returns</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">return_value</span><span class="p">)</span>
       <span class="n">reward_per_episode</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">returns</span><span class="p">))</span>
   <span class="n">episode_return_list</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">reward_per_episode</span><span class="p">)</span>

   <span class="k">print</span><span class="p">(</span><span class="s">'Game over.</span><span class="se">\n</span><span class="s">'</span><span class="p">)</span>
   <span class="n">env</span><span class="p">.</span><span class="n">destroy</span><span class="p">()</span>


<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="s">"__main__"</span><span class="p">:</span>
   <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">):</span>
       <span class="n">env</span> <span class="o">=</span> <span class="n">Robot_Gridworld</span><span class="p">()</span>

       <span class="n">dqn</span> <span class="o">=</span> <span class="n">DeepQLearning</span><span class="p">(</span><span class="n">env</span><span class="p">.</span><span class="n">n_actions</span><span class="p">,</span> <span class="n">env</span><span class="p">.</span><span class="n">n_features</span><span class="p">,</span>
                           <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span>
                           <span class="n">discount_factor</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span>
                           <span class="n">e_greedy</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span>
                           <span class="n">replace_target_iter</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span>
                           <span class="n">memory_size</span><span class="o">=</span><span class="mi">2000</span>
                           <span class="p">)</span>


       <span class="n">env</span><span class="p">.</span><span class="n">after</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">update</span><span class="p">)</span> <span class="c1">#Basic module in tkinter
</span>       <span class="n">env</span><span class="p">.</span><span class="n">mainloop</span><span class="p">()</span> <span class="c1">#Basic module in tkinter
</span>
   <span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">()</span>
   <span class="n">mean_return</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">.</span><span class="n">mean</span><span class="p">()</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">episode_return_list</span><span class="p">).</span><span class="n">T</span><span class="p">]</span>
   <span class="n">min_return</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">.</span><span class="nb">min</span><span class="p">()</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">episode_return_list</span><span class="p">).</span><span class="n">T</span><span class="p">]</span>
   <span class="n">max_return</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">.</span><span class="nb">max</span><span class="p">()</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">episode_return_list</span><span class="p">).</span><span class="n">T</span><span class="p">]</span>
</code></pre></div></div>

<p>í•™ìŠµ ê²°ê³¼ëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤.</p>

<ul>
  <li>ì²«ë²ˆì§¸ Gridworld (ì£¼í™© ë„¤ëª¨ X)
    <div style="text-align: left">
  <img src="/assets/img/post_images/dqn1.png" width="100%" />
  </div>
  </li>
  <li>ë‘ë²ˆì§¸ Gridworld (ì£¼í™© ë„¤ëª¨ O)
    <div style="text-align: left">
  <img src="/assets/img/post_images/dqn2.png" width="100%" />
  </div>
  </li>
</ul>

<p>ê·¸ë˜í”„ë¥¼ ë¹„êµí•´ë³´ë©´ ë‘ë²ˆì§¸ Gridworldë¡œ ëŒë ¸ì„ ë•Œ, ë³´ë‹¤ ë¹¨ë¦¬, ì ì€ ë¶„ì‚°ìœ¼ë¡œ ìµœì  policyë¥¼ ì°¾ì•„ê°€ëŠ” ê²ƒìœ¼ë¡œ ë³´ì¸ë‹¤. í•˜ì§€ë§Œ ë‘ë²ˆì§¸ GridworldëŠ” ë¦¬ì›Œë“œ 10ì„ ì£¼ëŠ” sub optimalí•œ ê²½ìš°ê°€ ì¶”ê°€ ë˜ì—ˆê¸° ë•Œë¬¸ì— ìì¹«í•˜ë©´ ë¦¬ì›Œë“œ 20ì„ ì£¼ëŠ” ë³´ë¬¼ì„ ì°¾ì•„ê°€ëŠ” ëŒ€ì‹ ì— 10ì„ ì£¼ëŠ” sub optimalì— ë¹ ì§ˆ ìˆ˜ ìˆë‹¤. ê·¸ëŸ´ ê²½ìš° batch sizeë¥¼ í‚¤ìš°ê±°ë‚˜, í•™ìŠµì´ ì§„í–‰ë˜ì–´ ê°ì— ë”°ë¼ learning rate ì„œì„œíˆ ê°ì†Œì‹œí‚´ìœ¼ë¡œì¨ sub optimalì— ë¹ ì§€ëŠ” ê²ƒì„ ë°©ì§€í•  ìˆ˜ ìˆë‹¤.</p>

<p><br />
Â </p>

<hr />

<p>ì°¸ê³  ë‚´ìš© ì¶œì²˜ :</p>
<ul>
  <li><a href="http://wiki.hash.kr/index.php/DQN">http://wiki.hash.kr/index.php/DQN</a></li>
  <li><a href="https://velog.io/@sjinu/%EA%B0%9C%EB%85%90%EC%A0%95%EB%A6%AC-7.-DQNDeep-Q-NEtwork">https://velog.io/@sjinu/%EA%B0%9C%EB%85%90%EC%A0%95%EB%A6%AC-7.-DQNDeep-Q-NEtwork</a></li>
</ul>

                </div>
            </section>

            <!-- Email subscribe form at the bottom of the page -->
            

            <footer class="post-full-footer">
                <!-- Everything inside the #author tags pulls data from the author -->
                <!-- #author-->
                
                    
                
                    
                        <section class="author-card">
                            
                                <img class="author-profile-image" src="/assets/img/style/beanie.svg" alt="Beanie" />
                            
                            <section class="author-card-content">
                                <h4 class="author-card-name"><a href="/author/Beanie">Beanie</a></h4>
                                
                                    <p>Hello, Iâ€™m Beanie, always pondering and crafting services to make life fun and convenient</p>
                                
                            </section>
                        </section>
                        <div class="post-full-footer-right">
                            <a class="author-card-button" href="/author/Beanie">Read More</a>
                        </div>
                    
                
                <!-- /author  -->
            </footer>

            <!-- If you use Disqus comments, just uncomment this block.
            The only thing you need to change is "test-apkdzgmqhj" - which
            should be replaced with your own Disqus site-id. -->
            
                <section class="post-full-comments">
                    <div id="disqus_thread"></div>
                    <script>
                        var disqus_config = function () {
                            var this_page_url = 'http://localhost:4000/Implement-DQN';
                            var this_page_identifier = '/Implement DQN';
                            var this_page_title = 'Deep Q-Network(DQN) êµ¬í˜„';
                        };
                        (function() {
                            var d = document, s = d.createElement('script');
                            s.src = 'https://Beanie.disqus.com/embed.js';
                            s.setAttribute('data-timestamp', +new Date());
                            (d.head || d.body).appendChild(s);
                        })();
                    </script>
                </section>
            

        </article>

    </div>
</main>

<!-- Links to Previous/Next posts -->
<aside class="read-next outer">
    <div class="inner">
        <div class="read-next-feed">
            
                
                
                
                
                    <article class="read-next-card"
                        
                            style="background-image: url(/assets/img/style/sky.png)"
                        
                    >
                        <header class="read-next-card-header">
                            <small class="read-next-card-header-sitetitle">&mdash; Beanie in the wind &mdash;</small>
                            
                                <h3 class="read-next-card-header-title"><a href="/tag/rl/">Rl</a></h3>
                            
                        </header>
                        <div class="read-next-divider"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 14.5s2 3 5 3 5.5-2.463 5.5-5.5S21 6.5 18 6.5c-5 0-7 11-12 11C2.962 17.5.5 15.037.5 12S3 6.5 6 6.5s4.5 3.5 4.5 3.5"/></svg>
</div>
                        <div class="read-next-card-content">
                            <ul>
                                
                                
                                  
                                
                                  
                                    
                                        
                                        
                                            <li><a href="/RecSys-&-RL-Top-%F0%9D%90%BE-Off-Policy-Correction-for-a-REINFORCE-Recommender-System">(ì‘ì„±ì¤‘) RecSys & RL - Top-ğ¾ Off-Policy Correction for a REINFORCE Recommender System</a></li>
                                        
                                    
                                  
                                
                                  
                                
                                  
                                    
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                    
                                        
                                        
                                            <li><a href="/(RL)-Value-Function-Approximation">(Reinforcement learning) Value Function Approximation</a></li>
                                        
                                    
                                  
                                
                                  
                                    
                                        
                                        
                                            <li><a href="/Implement-Q-learning-&-Double-Q-learning">Q-learning & Double Q-learning êµ¬í˜„</a></li>
                                        
                                    
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                    
                                        
                                        
                                    
                                  
                                
                                  
                                    
                                        
                                        
                                    
                                  
                                
                                  
                                    
                                        
                                        
                                    
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                            </ul>
                        </div>
                        <footer class="read-next-card-footer">
                            <a href="/tag/rl/">
                                
                                    See all 6 posts  â†’
                                
                            </a>
                        </footer>
                    </article>
                
            

            <!-- If there's a next post, display it using the same markup included from - partials/post-card.hbs -->
            
                

    <article class="post-card post-template">
        
            <a class="post-card-image-link" href="/Transformer">
                <div class="post-card-image" style="background-image: url(/assets/img/post_images/ai_cover2.jpg)"></div>
            </a>
        
        <div class="post-card-content">
            <a class="post-card-content-link" href="/Transformer">
                <header class="post-card-header">
                    
                        
                            
                                <span class="post-card-tags">Ai</span>
                            
                        
                    

                    <h2 class="post-card-title">Transformer</h2>
                </header>
                <section class="post-card-excerpt">
                    
                        <p>Transformerì€ recurrenceë‚˜ convolutionì—†ì´ attentionë§Œì„ ì‚¬ìš©í•˜ëŠ” ìƒˆë¡œìš´ sequence transduction modelì´ë‹¤. Transformerì€ Attention Is All You Need ë¼ëŠ” ë…¼ë¬¸ì—ì„œ ì²˜ìŒìœ¼ë¡œ ì œì•ˆë˜ì—ˆë‹¤.

</p>
                    
                </section>
            </a>
            <footer class="post-card-meta">
                
                    
                
                    
                        
                        <img class="author-profile-image" src="/assets/img/style/beanie.svg" alt="Beanie" />
                        
                        <span class="post-card-author">
                            <a href="/author/Beanie/">Beanie</a>
                        </span>
                    
                
                <span class="reading-time">
                    
                    
                      5 min read
                    
                </span>
            </footer>
        </div>
    </article>

            

            <!-- If there's a previous post, display it using the same markup included from - partials/post-card.hbs -->
            
                

    <article class="post-card post-template">
        
            <a class="post-card-image-link" href="/Implement-Bidirectional-Associative-Memory">
                <div class="post-card-image" style="background-image: url(/assets/img/post_images/ai_cover2.jpg)"></div>
            </a>
        
        <div class="post-card-content">
            <a class="post-card-content-link" href="/Implement-Bidirectional-Associative-Memory">
                <header class="post-card-header">
                    
                        
                            
                                <span class="post-card-tags">Ai</span>
                            
                        
                    

                    <h2 class="post-card-title">Bidirectional Associative Memory êµ¬í˜„</h2>
                </header>
                <section class="post-card-excerpt">
                    
                        <p>Bidirectional Associative Memory (BAM) ì´ë€?

Â 
BAM ì€ Hopfield modelì„ í™•ì¥í•œ ëª¨ë¸ì´ë‹¤.
ì—¬ê¸°ì„œ ë˜ Hopfield modelì´ë¼ëŠ” ê²ƒì´ ë“±ì¥í•˜ëŠ” ë°(..), ì ì‹œ ì •ë¦¬í•˜ê³  ë„˜ì–´ê°€ì.

</p>
                    
                </section>
            </a>
            <footer class="post-card-meta">
                
                    
                
                    
                        
                        <img class="author-profile-image" src="/assets/img/style/beanie.svg" alt="Beanie" />
                        
                        <span class="post-card-author">
                            <a href="/author/Beanie/">Beanie</a>
                        </span>
                    
                
                <span class="reading-time">
                    
                    
                      6 min read
                    
                </span>
            </footer>
        </div>
    </article>

            

        </div>
    </div>
</aside>

<!-- Floating header which appears on-scroll, included from includes/floating-header.hbs -->
<div class="floating-header">
    <div class="floating-header-logo">
        <a href="http://localhost:4000/">
            
                <img src="/assets/img/favicons/logo.png" alt="Beanie in the wind icon" />
            
            <span>Beanie in the wind</span>
        </a>
    </div>
    <span class="floating-header-divider">&mdash;</span>
    <div class="floating-header-title">Deep Q-Network(DQN) êµ¬í˜„</div>
    <div class="floating-header-share">
        <div class="floating-header-share-label">Share this <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
    <path d="M7.5 15.5V4a1.5 1.5 0 1 1 3 0v4.5h2a1 1 0 0 1 1 1h2a1 1 0 0 1 1 1H18a1.5 1.5 0 0 1 1.5 1.5v3.099c0 .929-.13 1.854-.385 2.748L17.5 23.5h-9c-1.5-2-5.417-8.673-5.417-8.673a1.2 1.2 0 0 1 1.76-1.605L7.5 15.5zm6-6v2m-3-3.5v3.5m6-1v2"/>
</svg>
</div>
        <a class="floating-header-share-tw" href="https://twitter.com/share?text=Deep+Q-Network%28DQN%29+%EA%B5%AC%ED%98%84&amp;url=https://beanie00.github.io/Implement-DQN"
            onclick="window.open(this.href, 'share-twitter', 'width=550,height=235');return false;">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32"><path d="M30.063 7.313c-.813 1.125-1.75 2.125-2.875 2.938v.75c0 1.563-.188 3.125-.688 4.625a15.088 15.088 0 0 1-2.063 4.438c-.875 1.438-2 2.688-3.25 3.813a15.015 15.015 0 0 1-4.625 2.563c-1.813.688-3.75 1-5.75 1-3.25 0-6.188-.875-8.875-2.625.438.063.875.125 1.375.125 2.688 0 5.063-.875 7.188-2.5-1.25 0-2.375-.375-3.375-1.125s-1.688-1.688-2.063-2.875c.438.063.813.125 1.125.125.5 0 1-.063 1.5-.25-1.313-.25-2.438-.938-3.313-1.938a5.673 5.673 0 0 1-1.313-3.688v-.063c.813.438 1.688.688 2.625.688a5.228 5.228 0 0 1-1.875-2c-.5-.875-.688-1.813-.688-2.75 0-1.063.25-2.063.75-2.938 1.438 1.75 3.188 3.188 5.25 4.25s4.313 1.688 6.688 1.813a5.579 5.579 0 0 1 1.5-5.438c1.125-1.125 2.5-1.688 4.125-1.688s3.063.625 4.188 1.813a11.48 11.48 0 0 0 3.688-1.375c-.438 1.375-1.313 2.438-2.563 3.188 1.125-.125 2.188-.438 3.313-.875z"/></svg>

        </a>
        <a class="floating-header-share-fb" href="https://www.facebook.com/sharer/sharer.php?u=https://beanie00.github.io/Implement-DQN"
            onclick="window.open(this.href, 'share-facebook','width=580,height=296');return false;">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32"><path d="M19 6h5V0h-5c-3.86 0-7 3.14-7 7v3H8v6h4v16h6V16h5l1-6h-6V7c0-.542.458-1 1-1z"/></svg>

        </a>
    </div>
    <progress class="progress" value="0">
        <div class="progress-container">
            <span class="progress-bar"></span>
        </div>
    </progress>
</div>


<!-- /post -->

<!-- The #contentFor helper here will send everything inside it up to the matching #block helper found in default.hbs -->


        <!-- Previous/next page links - displayed on every page -->
        

        <!-- The footer at the very bottom of the screen -->
        <footer class="site-footer outer">
            <div class="site-footer-content inner">
                <section class="copyright"><a href="http://localhost:4000/">Beanie in the wind</a> &copy; 2022</section>
                <section class="poweredby">Proudly published with <a href="https://jekyllrb.com/">Jekyll</a> &
                    <a href="https://pages.github.com/" target="_blank" rel="noopener">GitHub Pages</a> using
                    <a href="https://github.com/jekyllt/jasper2" target="_blank" rel="noopener">Jasper2</a></section>
                <nav class="site-footer-nav">
                    <a href="/">Latest Posts</a>
                    
                    
                    <a href="https://ghost.org" target="_blank" rel="noopener">Ghost</a>
                </nav>
            </div>
        </footer>

    </div>

    <!-- The big email subscribe modal content -->
    

    <!-- highlight.js -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.10.0/components/prism-abap.min.js"></script>
    <script>$(document).ready(function() {
      $('pre code').each(function(i, block) {
        hljs.highlightBlock(block);
      });
    });</script>

    <!-- jQuery + Fitvids, which makes all video embeds responsive -->
    <script
        src="https://code.jquery.com/jquery-3.2.1.min.js"
        integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4="
        crossorigin="anonymous">
    </script>
    <script type="text/javascript" src="/assets/js/jquery.fitvids.js"></script>
    <script type="text/javascript" src="https://demo.ghost.io/assets/js/jquery.fitvids.js?v=724281a32e"></script>


    <!-- Paginator increased to "infinit" in _config.yml -->
    <!-- if paginator.posts  -->
    <!-- <script>
        var maxPages = parseInt('');
    </script>
    <script src="/assets/js/infinitescroll.js"></script> -->
    <!-- /endif -->

    


    <!-- Add Google Analytics  -->
    <!-- Google Analytics Tracking code -->
 <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-69281367-1', 'auto');
  ga('send', 'pageview');

 </script>


    <!-- The #block helper will pull in data from the #contentFor other template files. In this case, there's some JavaScript which we only want to use in post.hbs, but it needs to be included down here, after jQuery has already loaded. -->
    
        <script>

// NOTE: Scroll performance is poor in Safari
// - this appears to be due to the events firing much more slowly in Safari.
//   Dropping the scroll event and using only a raf loop results in smoother
//   scrolling but continuous processing even when not scrolling
$(document).ready(function () {
    // Start fitVids
    var $postContent = $(".post-full-content");
    $postContent.fitVids();
    // End fitVids

    var progressBar = document.querySelector('progress');
    var header = document.querySelector('.floating-header');
    var title = document.querySelector('.post-full-title');

    var lastScrollY = window.scrollY;
    var lastWindowHeight = window.innerHeight;
    var lastDocumentHeight = $(document).height();
    var ticking = false;

    function onScroll() {
        lastScrollY = window.scrollY;
        requestTick();
    }

    function onResize() {
        lastWindowHeight = window.innerHeight;
        lastDocumentHeight = $(document).height();
        requestTick();
    }

    function requestTick() {
        if (!ticking) {
            requestAnimationFrame(update);
        }
        ticking = true;
    }

    function update() {
        var trigger = title.getBoundingClientRect().top + window.scrollY;
        var triggerOffset = title.offsetHeight + 35;
        var progressMax = lastDocumentHeight - lastWindowHeight;

        // show/hide floating header
        if (lastScrollY >= trigger + triggerOffset) {
            header.classList.add('floating-active');
        } else {
            header.classList.remove('floating-active');
        }

        progressBar.setAttribute('max', progressMax);
        progressBar.setAttribute('value', lastScrollY);

        ticking = false;
    }

    window.addEventListener('scroll', onScroll, {passive: true});
    window.addEventListener('resize', onResize, false);

    update();
});
</script>

    

    <!-- Ghost outputs important scripts and data with this tag - it should always be the very last thing before the closing body tag -->
    <!-- ghost_foot -->

</body>
</html>
