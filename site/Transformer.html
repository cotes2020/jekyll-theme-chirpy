<!DOCTYPE html>
<html>
<head>

    <!-- Document Settings -->
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />

    <!-- Base Meta -->
    <!-- dynamically fixing the title for tag/author pages -->



    <title>Transformer</title>
    <meta name="HandheldFriendly" content="True" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <!-- Styles'n'Scripts -->
    <link rel="stylesheet" type="text/css" href="/assets/built/screen.css" />
    <link rel="stylesheet" type="text/css" href="/assets/built/screen.edited.css" />
    <link rel="stylesheet" type="text/css" href="/assets/built/syntax.css" />
    <!-- highlight.js -->
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css">
    <style>.hljs { background: none; }</style>

    <!--[if IE]>
        <style>
            p, ol, ul{
                width: 100%;
            }
            blockquote{
                width: 100%;
            }
        </style>
    <![endif]-->
    
    <!-- This tag outputs SEO meta+structured data and other important settings -->
    <meta name="description" content="Seize the day" />
    <link rel="shortcut icon" href="http://localhost:4000/assets/img/favicons/favicon-32x32.png" type="image/png" />
    <link rel="canonical" href="http://localhost:4000/Transformer" />
    <meta name="referrer" content="no-referrer-when-downgrade" />

    <meta name="google-site-verification" content="X86eN2H5lW1jy6i7OLmOjBAyCf4N8PPVT0sBdIH57LE" />

     <!--title below is coming from _includes/dynamic_title-->
    <meta property="og:site_name" content="PIGBEAN Tech blog" />
    <meta property="og:type" content="website" />
    <meta property="og:title" content="Transformer" />
    <meta property="og:description" content="Transformer은 recurrence나 convolution없이 attention만을 사용하는 새로운 sequence transduction model이다. Background   기존의 seq2seq 모델은 인코더-디코더 구조로 구성되어 있었다. 인코더에서는 입력 시퀀스(ex&gt; 문장)를 하나의 벡터 표현으로 압축하고, 디코더는 이 벡터 표현을 통해 출력 시퀀스를 만들어냈다. 하지만 이 구조에서는 인코더가 입력 시퀀스를 압축하는 과정에서 정보가 일부 손실된다는 단점이 존재했는데, 그래서 이를 보정하기" />
    <meta property="og:url" content="http://localhost:4000/Transformer" />
    <meta property="og:image" content="http://localhost:4000/assets/img/post_images/ai_cover2.jpg" />
    <meta property="article:publisher" content="https://www.facebook.com/false" />
    <meta property="article:author" content="https://www.facebook.com/false" />
    <meta property="article:published_time" content="2022-05-16T13:02:00+09:00" />
    <meta property="article:modified_time" content="2022-05-16T13:02:00+09:00" />
    <meta property="article:tag" content="Ai" />
    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:title" content="Transformer" />
    <meta name="twitter:description" content="Transformer은 recurrence나 convolution없이 attention만을 사용하는 새로운 sequence transduction model이다. Background   기존의 seq2seq 모델은 인코더-디코더 구조로 구성되어 있었다. 인코더에서는 입력 시퀀스(ex&gt; 문장)를 하나의 벡터 표현으로 압축하고, 디코더는 이 벡터 표현을 통해 출력 시퀀스를 만들어냈다. 하지만 이 구조에서는 인코더가 입력 시퀀스를 압축하는 과정에서 정보가 일부 손실된다는 단점이 존재했는데, 그래서 이를 보정하기" />
    <meta name="twitter:url" content="http://localhost:4000/" />
    <meta name="twitter:image" content="http://localhost:4000/assets/img/post_images/ai_cover2.jpg" />
    <meta name="twitter:label1" content="Written by" />
    <meta name="twitter:data1" content="PIGBEAN Tech blog" />
    <meta name="twitter:label2" content="Filed under" />
    <meta name="twitter:data2" content="Ai" />
    <meta name="twitter:site" content="@false" />
    <meta name="twitter:creator" content="@false" />
    <meta property="og:image:width" content="1400" />
    <meta property="og:image:height" content="933" />
    <script src="https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js"></script>
    <script>mermaid.initialize({startOnLoad:true});</script>
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
        tex2jax: {
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
            inlineMath: [['$','$']]
        }
        });
    </script>
    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
    <meta http-equiv="cache-control" content="max-age=0" />
    <meta http-equiv="cache-control" content="no-cache" />
    <meta http-equiv="expires" content="0" />
    <meta http-equiv="expires" content="Tue, 01 Jan 1980 1:00:00 GMT" />
    <meta http-equiv="pragma" content="no-cache" />
    <script type="application/ld+json">
{
    "@context": "https://schema.org",
    "@type": "Website",
    "publisher": {
        "@type": "Organization",
        "name": "PIGBEAN Tech blog",
        "logo": "http://localhost:4000/assets/img/favicons/android-chrome-256x256.png"
    },
    "url": "http://localhost:4000/Transformer",
    "image": {
        "@type": "ImageObject",
        "url": "http://localhost:4000/assets/img/post_images/ai_cover2.jpg",
        "width": 2000,
        "height": 666
    },
    "mainEntityOfPage": {
        "@type": "WebPage",
        "@id": "http://localhost:4000/Transformer"
    },
    "description": "Transformer은 recurrence나 convolution없이 attention만을 사용하는 새로운 sequence transduction model이다. Background   기존의 seq2seq 모델은 인코더-디코더 구조로 구성되어 있었다. 인코더에서는 입력 시퀀스(ex&gt; 문장)를 하나의 벡터 표현으로 압축하고, 디코더는 이 벡터 표현을 통해 출력 시퀀스를 만들어냈다. 하지만 이 구조에서는 인코더가 입력 시퀀스를 압축하는 과정에서 정보가 일부 손실된다는 단점이 존재했는데, 그래서 이를 보정하기"
}
    </script>

    <!-- <script type="text/javascript" src="https://demo.ghost.io/public/ghost-sdk.min.js?v=724281a32e"></script>
    <script type="text/javascript">
    ghost.init({
    	clientId: "ghost-frontend",
    	clientSecret: "f84a07a72b17"
    });
    </script> -->

    <meta name="generator" content="Jekyll 3.6.2" />
    <link rel="alternate" type="application/rss+xml" title="Transformer" href="/feed.xml" />



</head>
<body class="post-template">

    <div class="site-wrapper">
        <!-- All the main content gets inserted here, index.hbs, post.hbs, etc -->
        <!-- default -->

<!-- The tag above means: insert everything in this file
into the {body} of the default.hbs template -->

<header class="site-header outer">
    <div class="inner">
        <nav class="site-nav">
    <div class="site-nav-left">
        
            
                <a class="site-nav-logo" href="http://localhost:4000/"><img src="/assets/img/favicons/android-chrome-256x256.png" alt="PIGBEAN Tech blog" /></a>
            
        
        
            <ul class="nav" role="menu">
    <li class="nav-home" role="menuitem"><a href="/">Home</a></li>
    <li class="nav-about" role="menuitem"><a href="/about/">About</a></li>
    <li class="nav-getting-started" role="menuitem"><a href="/tag/Catty/">Catty</a></li>
</ul>

        
    </div>
    <div class="site-nav-right">
        <div class="social-links">
            
            
        </div>
        
    </div>
</nav>

    </div>
</header>

<!-- Everything inside the #post tags pulls data from the post -->
<!-- #post -->

<main id="site-main" class="site-main outer" role="main">
    <div class="inner">

        <article class="post-full  tag-ai post ">

            <header class="post-full-header">
                <section class="post-full-meta">
                    <time class="post-full-meta-date" datetime="16 May 2022">16 May 2022</time>
                    
                        <span class="date-divider">/</span>
                        
                            
                               <a href='/tag/ai/'>AI</a>
                            
                        
                    
                </section>
                <h1 class="post-full-title">Transformer</h1>
            </header>

            
            <figure class="post-full-image" style="background-image: url(/assets/img/post_images/ai_cover2.jpg)">
            </figure>
            

            <section class="post-full-content">
                <div class="kg-card-markdown">
                    <p><strong>Transformer은 recurrence나 convolution없이 attention만을 사용하는 새로운 sequence transduction model</strong>이다.</p>

<h2 id="background">Background</h2>
<p> </p>

<p>기존의 seq2seq 모델은 인코더-디코더 구조로 구성되어 있었다. 인코더에서는 입력 시퀀스(ex&gt; 문장)를 하나의 벡터 표현으로 압축하고, 디코더는 이 벡터 표현을 통해 출력 시퀀스를 만들어냈다. 하지만 이 구조에서는 인코더가 입력 시퀀스를 압축하는 과정에서 정보가 일부 손실된다는 단점이 존재했는데, 그래서 이를 보정하기 위하여 어텐션이 사용되었다. 이 때 어텐션은 인코더 쪽의 hidden variable과 디코더 쪽의 hidden variable간의 유사성을 비교하였다. 이 어텐션을 이용하면 입력과 출력 시퀀스의 distance에 대한 고려 없이 둘간의 의존성을 모델링할 수 있다.</p>

<p>본 논문에서는 이렇게 어텐션을 RNN의 단점을 보정하는 역할로서 사용하는 것이 아니라 <strong>어텐션</strong> 만을 사용해 인코더-디코더를 만들어보는 것을 제안한다.</p>

<p> </p>
<h2 id="모델-아키텍쳐">모델 아키텍쳐</h2>
<p> </p>
<div style="text-align: left">
  <img src="/assets/img/post_images/transformer1.jpeg" width="100%" />
</div>

<h3 id="encoder-and-decoder-stacks">Encoder and Decoder Stacks</h3>

<h4 id="encoder">Encoder</h4>

<p>트랜스포머는 RNN 없이 인코더-디코더를 구성한다. RNN이 있는 구조에서는 인코더와 디코더에 각각 존재하는 RNN 한 개가 t개의 time step를 가지는 구조였다면, 트랜스포머는 인코더, 디코더 자체가 N개(본 논문에서는 6개)씩 존재한다. 각 6개의 layer은 다시 2개의 sub-layer을 가진다. 여기서 첫 번째 sub-layer은 <strong>multi-head self-attention mechanism</strong>이고, 두번째 sub-layer은 <strong>position-wise fully connected feed-forward 네트워크</strong> 이다. 또한, Encoder에서 layer nomalization을 수행한 이후에 각 sub-layers에서 residual connection을 해준다.</p>

<h4 id="decoder">Decoder</h4>
<p>Encoder와 마찬가지로 6개의 layer을 stack하였고, 동일한 2개의 sub-layer을 가지며 이에 떠해 multi head attention을 수행하는 3번째 sub-layer가 추가된다. 또한 마찬가지로 layer nomalization 이후 각 sub-layer에서 residual connection을 해준다.</p>

<p>반면 Encoder와는 달리 self-attention을 수행하는 sub-layer에 조금 수정을 가했는데,</p>

<h3 id="attention">Attention</h3>

<p>Attention 함수는 query와 key-value pair (key, value) 의 집합을 output으로 매핑한다. 좀 더 자세히 말하면, output은 value들의 weighted sum으로 계산되는 데, 이 때, 각 value에 대응되는 weight 값은 query와 대응되는 key간의 compatibility function으로 계산된다.</p>

<div style="text-align: left">
  <img src="/assets/img/post_images/transformer2.jpeg" width="100%" />
</div>

<h4 id="scaled-dot-product-attention">Scaled Dot-Product Attention</h4>

<p>Compatibility 함수로 대표적으로 <strong>scaled dot product</strong> 를 사용한다. Scaled dot product에서 각 value의 weight은 다음 식으로 계산된다.</p>

\[Attention(Q, K, V) = softmax( \frac{QK^{T}}{\sqrt{d_{k}}} ) V\]

<p>이 때, 식을 확인해보면 $ \frac{1}{\sqrt{d_{k}}} $ 를 추가로 곱해주는 것을 볼 수 있다. 이는 $ d_{k} $ 가 큰 수 일 때, dot product가 너무 큰 값을 가져 softmax function이 매우 작은 gradient 값을 가지게 된다. 따라서 dot product를 $ d_{k} $ 로 나눠 이를 보정해준다.</p>

<h4 id="multi-head-attention">Multi-Head Attention</h4>
<p>어텐션을 큰 dimension에 대하여 한 번에 적용하면 학습 속도가 오래 걸린다. 따라서 본 논문에서는 어텐션을 사용할 때 한 번에 적용하는 것이 아니라 여러개로 분할하여 병렬로 수행한 뒤 이를 다시 하나로 합치는 방법을 제안하였다. 즉, 전체 dimension을 h로 나눠서 병렬로 attention을 h번 적용한다.</p>

<ol>
  <li>query와 key, value를 각각 $ d_{k}, d_{k}, d_{v} $ 차원에 linear projection한다.</li>
  <li>이렇게 projection 된 버전의 query, key, value를 가지고 Scaled dot product attention을 수행한다.</li>
  <li>이 과정을 h번 반복한다.</li>
  <li>구해진 h개의 벡터를 합치고 다시 project 하여 최종 값을 얻는다.</li>
</ol>

<h3 id="position-wise-feed-forward-networks">Position-wise Feed-Forward Networks</h3>
<p>sub layer에 적용되는 attention에 추가로, 인코더, 디코더의 각 레이어는 각 position에 동일하게 적용되는 fully connected feed-forward network를 가진다. 이 네트워크는 ReLu activation을 사이에 둔 두개의 linear transformation으로 구성된다.</p>

\[FFN(x) = max(0, xW_{1} + b_{1})W_{2} + b_{2}\]

<h3 id="embeddings-and-softmax">Embeddings and Softmax</h3>
<p>다른 sequence transduction 모델과 유사하게, 입력 토큰들을 출력 토큰들로 변환해주는 데 학습된 embedding을 사용한다. 또한, 디코더 출력을 다음 토큰의 확률로 바꿔주는데 학습된 transformation과 softmax 함수를 사용한다.</p>

<h3 id="positional-encoding">Positional Encoding</h3>

<p>트랜스포머 모델에서는 recurrence도, convolution도 사용하지 않는다. 따라서 모델이 시퀀스의 순서 정보를 처리하기 위해서는 시퀀스에 있는 각 토큰의 상대 위치 혹은 절대 위치 정보를 추가로 알려줘야 한다. 이를 위해서 인코더, 디코더에 들어가기 전에 각각의 하위 레이어인 임베딩 레이어에 <strong>positional encoding</strong>이 추가하여 sequence에 순서를 준다.</p>

<p>positional encoding는 다양한 방법으로 구할 수 있는데, 논문에서는 다양한 주파수의 사인, 코사인 함수를 사용하여 이 값을 계산한다.</p>

<p>이처럼 positional encoding을 사용하면 시퀀스의 순서 정보를 보존할 수 있게 된다. 이후 인코더와 디코더에서는 같은 단어를 입력 받아도 순서 정보에 따라 다른 벡터 값을 처리하게 된다.</p>

<p> </p>
<h2 id="training">Training</h2>
<p> </p>

<h3 id="training-data-and-batching">Training Data and Batching</h3>
<p>학습에는 4.5백만개의 setence pair로 구성된 standard WMT 2014 English-German dataset을 사용하였다 또한, English-French 학습에는 보다 큰 (36M) WMT 2014 English-Frensh dataset을 사용하였다. sentence pair은 길이에 따라 batch로 묶었고, 각 batch는 약 25000개의 source token과 약 25000개의 target token으로 구성되어 있다.</p>

<h3 id="optimizer">Optimizer</h3>
<p>Adam optimizer을 사용하였다.</p>

<h3 id="regularization">Regularization</h3>
<p>정규화 방식으로 Residual dropout을 사용하였다.</p>

<p> </p>
<h2 id="result">Result</h2>
<p> </p>

<h3 id="machine-translation">Machine Translation</h3>
<h3 id="model-variance">Model Variance</h3>

                </div>
            </section>

            <!-- Email subscribe form at the bottom of the page -->
            

            <footer class="post-full-footer">
                <!-- Everything inside the #author tags pulls data from the author -->
                <!-- #author-->
                
                    
                
                    
                        <section class="author-card">
                            
                                <img class="author-profile-image" src="/assets/img/style/beanie.png" alt="Bean" />
                            
                            <section class="author-card-content">
                                <h4 class="author-card-name"><a href="/author/Bean">Beanie</a></h4>
                                
                                    <p>Hello, I’m Beanie, always pondering and crafting services to make life fun and convenient</p>
                                
                            </section>
                        </section>
                        <div class="post-full-footer-right">
                            <a class="author-card-button" href="/author/Bean">Read More</a>
                        </div>
                    
                
                <!-- /author  -->
            </footer>

            <!-- If you use Disqus comments, just uncomment this block.
            The only thing you need to change is "test-apkdzgmqhj" - which
            should be replaced with your own Disqus site-id. -->
            
                <section class="post-full-comments">
                    <div id="disqus_thread"></div>
                    <script>
                        var disqus_config = function () {
                            var this_page_url = 'http://localhost:4000/Transformer';
                            var this_page_identifier = '/Transformer';
                            var this_page_title = 'Transformer';
                        };
                        (function() {
                            var d = document, s = d.createElement('script');
                            s.src = 'https://Beanie.disqus.com/embed.js';
                            s.setAttribute('data-timestamp', +new Date());
                            (d.head || d.body).appendChild(s);
                        })();
                    </script>
                </section>
            

        </article>

    </div>
</main>

<!-- Links to Previous/Next posts -->
<aside class="read-next outer">
    <div class="inner">
        <div class="read-next-feed">
            
                
                
                
                
                    <article class="read-next-card"
                        
                            style="background-image: url(/assets/img/style/bean3.jpg)"
                        
                    >
                        <header class="read-next-card-header">
                            <small class="read-next-card-header-sitetitle">&mdash; PIGBEAN Tech blog &mdash;</small>
                            
                                <h3 class="read-next-card-header-title"><a href="/tag/ai/">Ai</a></h3>
                            
                        </header>
                        <div class="read-next-divider"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 14.5s2 3 5 3 5.5-2.463 5.5-5.5S21 6.5 18 6.5c-5 0-7 11-12 11C2.962 17.5.5 15.037.5 12S3 6.5 6 6.5s4.5 3.5 4.5 3.5"/></svg>
</div>
                        <div class="read-next-card-content">
                            <ul>
                                
                                
                                  
                                
                                  
                                    
                                  
                                
                                  
                                
                                  
                                    
                                        
                                        
                                            <li><a href="/Implement-Bidirectional-Associative-Memory">Bidirectional Associative Memory 구현</a></li>
                                        
                                    
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                    
                                        
                                        
                                            <li><a href="/Dropout">Dropout (Mathmatical approach)</a></li>
                                        
                                    
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                    
                                        
                                        
                                            <li><a href="/Implement-Multi-layer-perceptron-(from-scratch)">Implement Multi layer perceptron (from scratch)</a></li>
                                        
                                    
                                  
                                
                                  
                                    
                                        
                                        
                                    
                                  
                                
                                  
                                    
                                        
                                        
                                    
                                  
                                
                                  
                                    
                                        
                                        
                                    
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                            </ul>
                        </div>
                        <footer class="read-next-card-footer">
                            <a href="/tag/ai/">
                                
                                    See all 6 posts  →
                                
                            </a>
                        </footer>
                    </article>
                
            

            <!-- If there's a next post, display it using the same markup included from - partials/post-card.hbs -->
            
                

    <article class="post-card post-template">
        
            <a class="post-card-image-link" href="/Introduce-Catty,-the-resource-based-note-taking-app">
                <div class="post-card-image" style="background-image: url(/assets/img/post_images/catty.png)"></div>
            </a>
        
        <div class="post-card-content">
            <a class="post-card-content-link" href="/Introduce-Catty,-the-resource-based-note-taking-app">
                <header class="post-card-header">
                    
                        
                            
                                <span class="post-card-tags">Catty</span>
                            
                        
                    

                    <h2 class="post-card-title">리소스 기반 노트 작성 서비스 Catty 소개</h2>
                </header>
                <section class="post-card-excerpt">
                    
                        <p>작년 11월부터 틈틈히 공부겸 사이드 프로젝트 겸 Catty 서비스를 개발하였다. 이번 글에서는 Catty에 넣은 다양한 기능들을 소개하고 다음글에서는 회고 형식으로 지금껏 개발하면서 느끼고 생각한 것들을 정리해보려고 한다.

</p>
                    
                </section>
            </a>
            <footer class="post-card-meta">
                
                    
                
                    
                        
                        <img class="author-profile-image" src="/assets/img/style/beanie.png" alt="Beanie" />
                        
                        <span class="post-card-author">
                            <a href="/author/Bean/">Beanie</a>
                        </span>
                    
                
                <span class="reading-time">
                    
                    
                      3 min read
                    
                </span>
            </footer>
        </div>
    </article>

            

            <!-- If there's a previous post, display it using the same markup included from - partials/post-card.hbs -->
            
                

    <article class="post-card post-template">
        
            <a class="post-card-image-link" href="/Implement-DQN">
                <div class="post-card-image" style="background-image: url(/assets/img/post_images/ai_cover.jpg)"></div>
            </a>
        
        <div class="post-card-content">
            <a class="post-card-content-link" href="/Implement-DQN">
                <header class="post-card-header">
                    
                        
                            
                               <span class="post-card-tags">Rl</span>
                            
                        
                            
                                <span class="post-card-tags">Coding</span>
                            
                        
                    

                    <h2 class="post-card-title">Deep Q-Network(DQN) 구현</h2>
                </header>
                <section class="post-card-excerpt">
                    
                        <p> 
DQN 이란?
 

</p>
                    
                </section>
            </a>
            <footer class="post-card-meta">
                
                    
                
                    
                        
                        <img class="author-profile-image" src="/assets/img/style/beanie.png" alt="Beanie" />
                        
                        <span class="post-card-author">
                            <a href="/author/Bean/">Beanie</a>
                        </span>
                    
                
                <span class="reading-time">
                    
                    
                      4 min read
                    
                </span>
            </footer>
        </div>
    </article>

            

        </div>
    </div>
</aside>

<!-- Floating header which appears on-scroll, included from includes/floating-header.hbs -->
<div class="floating-header">
    <div class="floating-header-logo">
        <a href="http://localhost:4000/">
            
                <img src="/assets/img/favicons/favicon-32x32.png" alt="PIGBEAN Tech blog icon" />
            
            <span>PIGBEAN Tech blog</span>
        </a>
    </div>
    <span class="floating-header-divider">&mdash;</span>
    <div class="floating-header-title">Transformer</div>
    <div class="floating-header-share">
        <div class="floating-header-share-label">Share this <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
    <path d="M7.5 15.5V4a1.5 1.5 0 1 1 3 0v4.5h2a1 1 0 0 1 1 1h2a1 1 0 0 1 1 1H18a1.5 1.5 0 0 1 1.5 1.5v3.099c0 .929-.13 1.854-.385 2.748L17.5 23.5h-9c-1.5-2-5.417-8.673-5.417-8.673a1.2 1.2 0 0 1 1.76-1.605L7.5 15.5zm6-6v2m-3-3.5v3.5m6-1v2"/>
</svg>
</div>
        <a class="floating-header-share-tw" href="https://twitter.com/share?text=Transformer&amp;url=https://beanie00.github.io/Transformer"
            onclick="window.open(this.href, 'share-twitter', 'width=550,height=235');return false;">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32"><path d="M30.063 7.313c-.813 1.125-1.75 2.125-2.875 2.938v.75c0 1.563-.188 3.125-.688 4.625a15.088 15.088 0 0 1-2.063 4.438c-.875 1.438-2 2.688-3.25 3.813a15.015 15.015 0 0 1-4.625 2.563c-1.813.688-3.75 1-5.75 1-3.25 0-6.188-.875-8.875-2.625.438.063.875.125 1.375.125 2.688 0 5.063-.875 7.188-2.5-1.25 0-2.375-.375-3.375-1.125s-1.688-1.688-2.063-2.875c.438.063.813.125 1.125.125.5 0 1-.063 1.5-.25-1.313-.25-2.438-.938-3.313-1.938a5.673 5.673 0 0 1-1.313-3.688v-.063c.813.438 1.688.688 2.625.688a5.228 5.228 0 0 1-1.875-2c-.5-.875-.688-1.813-.688-2.75 0-1.063.25-2.063.75-2.938 1.438 1.75 3.188 3.188 5.25 4.25s4.313 1.688 6.688 1.813a5.579 5.579 0 0 1 1.5-5.438c1.125-1.125 2.5-1.688 4.125-1.688s3.063.625 4.188 1.813a11.48 11.48 0 0 0 3.688-1.375c-.438 1.375-1.313 2.438-2.563 3.188 1.125-.125 2.188-.438 3.313-.875z"/></svg>

        </a>
        <a class="floating-header-share-fb" href="https://www.facebook.com/sharer/sharer.php?u=https://beanie00.github.io/Transformer"
            onclick="window.open(this.href, 'share-facebook','width=580,height=296');return false;">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32"><path d="M19 6h5V0h-5c-3.86 0-7 3.14-7 7v3H8v6h4v16h6V16h5l1-6h-6V7c0-.542.458-1 1-1z"/></svg>

        </a>
    </div>
    <progress class="progress" value="0">
        <div class="progress-container">
            <span class="progress-bar"></span>
        </div>
    </progress>
</div>


<!-- /post -->

<!-- The #contentFor helper here will send everything inside it up to the matching #block helper found in default.hbs -->


        <!-- Previous/next page links - displayed on every page -->
        

        <!-- The footer at the very bottom of the screen -->
        <footer class="site-footer outer">
            <div class="site-footer-content inner">
                <section class="copyright"><a href="http://localhost:4000/">PIGBEAN Tech blog</a> &copy; 2022</section>
                <section class="poweredby">Proudly published with <a href="https://jekyllrb.com/">Jekyll</a> &
                    <a href="https://pages.github.com/" target="_blank" rel="noopener">GitHub Pages</a> using
                    <a href="https://github.com/jekyllt/jasper2" target="_blank" rel="noopener">Jasper2</a></section>
                <nav class="site-footer-nav">
                    <a href="/">Latest Posts</a>
                    
                    
                    <a href="https://ghost.org" target="_blank" rel="noopener">Ghost</a>
                </nav>
            </div>
        </footer>

    </div>

    <!-- The big email subscribe modal content -->
    

    <!-- highlight.js -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.10.0/components/prism-abap.min.js"></script>
    <script>$(document).ready(function() {
      $('pre code').each(function(i, block) {
        hljs.highlightBlock(block);
      });
    });</script>

    <!-- jQuery + Fitvids, which makes all video embeds responsive -->
    <script
        src="https://code.jquery.com/jquery-3.2.1.min.js"
        integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4="
        crossorigin="anonymous">
    </script>
    <script type="text/javascript" src="/assets/js/jquery.fitvids.js"></script>
    <script type="text/javascript" src="https://demo.ghost.io/assets/js/jquery.fitvids.js?v=724281a32e"></script>


    <!-- Paginator increased to "infinit" in _config.yml -->
    <!-- if paginator.posts  -->
    <!-- <script>
        var maxPages = parseInt('');
    </script>
    <script src="/assets/js/infinitescroll.js"></script> -->
    <!-- /endif -->

    


    <!-- Add Google Analytics  -->
    <!-- Google Analytics Tracking code -->
 <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-69281367-1', 'auto');
  ga('send', 'pageview');

 </script>


    <!-- The #block helper will pull in data from the #contentFor other template files. In this case, there's some JavaScript which we only want to use in post.hbs, but it needs to be included down here, after jQuery has already loaded. -->
    
        <script>

// NOTE: Scroll performance is poor in Safari
// - this appears to be due to the events firing much more slowly in Safari.
//   Dropping the scroll event and using only a raf loop results in smoother
//   scrolling but continuous processing even when not scrolling
$(document).ready(function () {
    // Start fitVids
    var $postContent = $(".post-full-content");
    $postContent.fitVids();
    // End fitVids

    var progressBar = document.querySelector('progress');
    var header = document.querySelector('.floating-header');
    var title = document.querySelector('.post-full-title');

    var lastScrollY = window.scrollY;
    var lastWindowHeight = window.innerHeight;
    var lastDocumentHeight = $(document).height();
    var ticking = false;

    function onScroll() {
        lastScrollY = window.scrollY;
        requestTick();
    }

    function onResize() {
        lastWindowHeight = window.innerHeight;
        lastDocumentHeight = $(document).height();
        requestTick();
    }

    function requestTick() {
        if (!ticking) {
            requestAnimationFrame(update);
        }
        ticking = true;
    }

    function update() {
        var trigger = title.getBoundingClientRect().top + window.scrollY;
        var triggerOffset = title.offsetHeight + 35;
        var progressMax = lastDocumentHeight - lastWindowHeight;

        // show/hide floating header
        if (lastScrollY >= trigger + triggerOffset) {
            header.classList.add('floating-active');
        } else {
            header.classList.remove('floating-active');
        }

        progressBar.setAttribute('max', progressMax);
        progressBar.setAttribute('value', lastScrollY);

        ticking = false;
    }

    window.addEventListener('scroll', onScroll, {passive: true});
    window.addEventListener('resize', onResize, false);

    update();
});
</script>

    

    <!-- Ghost outputs important scripts and data with this tag - it should always be the very last thing before the closing body tag -->
    <!-- ghost_foot -->

</body>
</html>
